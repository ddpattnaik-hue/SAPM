{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a262d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset Classes Based Portfolio Optimization and Analyses\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew, kurtosis, ttest_rel, f_oneway, wilcoxon, ttest_1samp, ttest_ind, shapiro, t\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.dates import DateFormatter, YearLocator\n",
    "import warnings\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional imports\n",
    "try:\n",
    "    from pmdarima import auto_arima\n",
    "    PMDARIMA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PMDARIMA_AVAILABLE = False\n",
    "    print(\"pmdarima not installed. Skipping Auto-ARIMA model.\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"xgboost not installed. Skipping XGBoost model.\")\n",
    "\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "    print(\"tensorflow not installed. Skipping LSTM model.\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d68d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "file_path = \"C:/Users/IMI/Documents/Courses/SAPM/AY 2025-26/R-Exercises/portfolio_data_extended.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Data file not found at {file_path}\")\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "print(f\"Removed {df['Date'].isna().sum()} rows with invalid dates\")\n",
    "df = df.dropna(subset=['Date'])\n",
    "print(f\"Removed {df.index.duplicated().sum()} duplicate dates\")\n",
    "df = df[~df['Date'].duplicated(keep='first')]\n",
    "df.set_index('Date', inplace=True)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data\n",
    "if 'Sensex' not in df.columns:\n",
    "    raise ValueError(\"Column 'Sensex' not found in the dataset\")\n",
    "if (df <= 0).any().any():\n",
    "    print(\"Warning: Non-positive values found in data, replacing with forward fill\")\n",
    "    df = df.where(df > 0).fillna(method='ffill')\n",
    "\n",
    "if (~np.isfinite(df)).any().any():\n",
    "    print(\"Warning: Non-finite values in data, replacing with forward fill\")\n",
    "    df = df.where(np.isfinite(df)).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics\n",
    "print(\"\\nData Diagnostics:\")\n",
    "print(\"Is index monotonic increasing?\", df.index.is_monotonic_increasing)\n",
    "print(\"Number of duplicated dates:\", df.index.duplicated().sum())\n",
    "print(\"Any NaT values in index?\", df.index.isna().sum())\n",
    "print(\"First 10 dates:\", df.index[:10])\n",
    "print(\"Last 10 dates:\", df.index[-10:])\n",
    "print(\"Length of df:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886cf8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns\n",
    "log_returns = np.log(df / df.shift(1)).dropna()\n",
    "print(\"\\nLog Returns Diagnostics:\")\n",
    "print(\"Is log_returns index monotonic increasing?\", log_returns.index.is_monotonic_increasing)\n",
    "print(\"Number of duplicated dates in log_returns:\", log_returns.index.duplicated().sum())\n",
    "print(\"Any NaT values in log_returns index?\", log_returns.index.isna().sum())\n",
    "print(\"Any non-finite values in log_returns:\", (~np.isfinite(log_returns)).sum().sum())\n",
    "if (~np.isfinite(log_returns)).any().any():\n",
    "    print(\"Warning: Non-finite values in log_returns, replacing with 0\")\n",
    "    log_returns = log_returns.where(np.isfinite(log_returns), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b03b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define market and asset returns\n",
    "market_returns = log_returns['Sensex']\n",
    "log_returns_subset = log_returns.drop(columns=['Sensex'], errors='ignore')\n",
    "num_assets = len(log_returns_subset.columns)\n",
    "\n",
    "# Annualize covariance matrix with Ledoit-Wolf shrinkage\n",
    "cov_matrix = LedoitWolf().fit(log_returns).covariance_ * 252\n",
    "port_cov_matrix = LedoitWolf().fit(log_returns_subset).covariance_ * 252\n",
    "market_var = cov_matrix[log_returns.columns.get_loc('Sensex'), log_returns.columns.get_loc('Sensex')]\n",
    "asset_market_cov = cov_matrix[log_returns_subset.columns.get_indexer(log_returns_subset.columns), log_returns.columns.get_loc('Sensex')]\n",
    "\n",
    "# Check covariance matrix\n",
    "cond_number = np.linalg.cond(port_cov_matrix)\n",
    "print(f\"Covariance matrix condition number: {cond_number:.2e}\")\n",
    "if cond_number > 1e6:\n",
    "    print(\"Warning: Covariance matrix is ill-conditioned, applying regularization\")\n",
    "    port_cov_matrix += np.eye(port_cov_matrix.shape[0]) * 1e-4\n",
    "\n",
    "# Set risk-free rate and market return\n",
    "risk_free_rate = 0.0696\n",
    "market_return = market_returns.mean() * 252\n",
    "if not np.isfinite(market_return):\n",
    "    print(\"Warning: Non-finite market return, setting to 0\")\n",
    "    market_return = 0\n",
    "\n",
    "# Asset class mapping\n",
    "asset_class_groups = {\n",
    "    'Equities': [\n",
    "        'Reliance Industries', 'HDFC Bank', 'Tata Consultancy Services', 'ICICI Bank', 'Infosys',\n",
    "        'Bharti Airtel', 'State Bank of India', 'Hindustan Unilever', 'ITC', 'Kotak Mahindra Bank',\n",
    "        'Larsen & Toubro', 'Axis Bank', 'Asian Paints', 'Maruti Suzuki India', 'Sun Pharmaceutical Industries',\n",
    "        'Bajaj Finance', 'Nestle India', 'HCL Technologies', 'Mahindra & Mahindra', 'Titan Company',\n",
    "        'UltraTech Cement', 'Power Grid Corporation of India', 'NTPC', 'Tata Motors', 'IndusInd Bank',\n",
    "        'Bajaj Auto', 'Tech Mahindra', 'JSW Steel', 'Wipro', 'Adani Enterprises'\n",
    "    ],\n",
    "    'Forex': ['USD/INR', 'EUR/INR'],\n",
    "    'Gold': ['Gold BeES']\n",
    "}\n",
    "\n",
    "target_exposures = {\n",
    "    'Equities': 0.7,\n",
    "    'Forex': 0.15,\n",
    "    'Gold': 0.15\n",
    "}\n",
    "\n",
    "# Validate asset names\n",
    "all_assets = set(log_returns_subset.columns)\n",
    "for asset_class, assets in asset_class_groups.items():\n",
    "    invalid_assets = [asset for asset in assets if asset not in all_assets]\n",
    "    if invalid_assets:\n",
    "        print(f\"Warning: Invalid asset names in {asset_class}: {invalid_assets}\")\n",
    "\n",
    "asset_class_indices = {}\n",
    "for asset_class, assets in asset_class_groups.items():\n",
    "    indices = [log_returns_subset.columns.get_loc(asset) for asset in assets if asset in log_returns_subset.columns]\n",
    "    asset_class_indices[asset_class] = indices\n",
    "print(\"\\nAsset Class Indices:\", asset_class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ec513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def calc_standard_deviation(weights, cov_matrix):\n",
    "    try:\n",
    "        variance = weights.T @ cov_matrix @ weights\n",
    "        if not np.isfinite(variance) or variance <= 0:\n",
    "            return np.nan\n",
    "        return np.sqrt(variance)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_standard_deviation: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def calc_expected_return(weights, returns):\n",
    "    try:\n",
    "        ret = np.sum(returns.mean() * weights) * 252\n",
    "        return ret if np.isfinite(ret) else np.nan\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_expected_return: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def calc_sharpe_ratio(weights, returns, cov_matrix, rf_rate):\n",
    "    try:\n",
    "        port_return = calc_expected_return(weights, returns)\n",
    "        port_std = calc_standard_deviation(weights, cov_matrix)\n",
    "        if not np.isfinite(port_return) or not np.isfinite(port_std) or port_std == 0:\n",
    "            return np.nan\n",
    "        return (port_return - rf_rate) / port_std\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_sharpe_ratio: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def calc_beta(weights, asset_market_cov, market_var):\n",
    "    try:\n",
    "        port_market_cov = weights @ asset_market_cov\n",
    "        if not np.isfinite(port_market_cov) or market_var == 0:\n",
    "            return np.nan\n",
    "        return port_market_cov / market_var\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_beta: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def calc_treynor_ratio(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var):\n",
    "    try:\n",
    "        port_return = calc_expected_return(weights, returns)\n",
    "        port_beta = calc_beta(weights, asset_market_cov, market_var)\n",
    "        if not np.isfinite(port_return) or not np.isfinite(port_beta) or port_beta == 0:\n",
    "            return np.nan\n",
    "        return (port_return - rf_rate) / port_beta\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_treynor_ratio: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def calc_jensens_alpha(weights, returns, cov_matrix, rf_rate, mkt_return, asset_market_cov, market_var):\n",
    "    try:\n",
    "        port_return = calc_expected_return(weights, returns)\n",
    "        port_beta = calc_beta(weights, asset_market_cov, market_var)\n",
    "        if not np.isfinite(port_return) or not np.isfinite(port_beta):\n",
    "            return np.nan\n",
    "        return port_return - (rf_rate + port_beta * (mkt_return - rf_rate))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_jensens_alpha: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def calc_var(weights, returns, alpha=0.05):\n",
    "    try:\n",
    "        port_returns = returns @ weights\n",
    "        if not np.isfinite(port_returns).all():\n",
    "            return np.nan\n",
    "        return np.percentile(port_returns, 100 * alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_var: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def calc_cvar(weights, returns, alpha=0.05):\n",
    "    try:\n",
    "        port_returns = returns @ weights\n",
    "        if not np.isfinite(port_returns).all():\n",
    "            return np.nan\n",
    "        var = calc_var(weights, returns, alpha)\n",
    "        if np.isnan(var):\n",
    "            return np.nan\n",
    "        cvar = port_returns[port_returns <= var].mean()\n",
    "        return cvar if np.isfinite(cvar) else np.nan\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_cvar: {e}\")\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective functions\n",
    "def calc_neg_sharpe_ratio(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var):\n",
    "    try:\n",
    "        sharpe = calc_sharpe_ratio(weights, returns, cov_matrix, rf_rate)\n",
    "        return -sharpe if np.isfinite(sharpe) else np.inf\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_neg_sharpe_ratio: {e}\")\n",
    "        return np.inf\n",
    "\n",
    "def calc_variance(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var):\n",
    "    try:\n",
    "        variance = weights.T @ cov_matrix @ weights\n",
    "        return variance if np.isfinite(variance) else np.inf\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_variance: {e}\")\n",
    "        return np.inf\n",
    "\n",
    "def neg_var(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var):\n",
    "    try:\n",
    "        var = calc_var(weights, returns)\n",
    "        return -var if np.isfinite(var) else np.inf\n",
    "    except Exception as e:\n",
    "        print(f\"Error in neg_var: {e}\")\n",
    "        return np.inf\n",
    "\n",
    "def neg_cvar(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var):\n",
    "    try:\n",
    "        cvar = calc_cvar(weights, returns)\n",
    "        return -cvar if np.isfinite(cvar) else np.inf\n",
    "    except Exception as e:\n",
    "        print(f\"Error in neg_cvar: {e}\")\n",
    "        return np.inf\n",
    "\n",
    "def calc_neg_treynor_ratio(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var):\n",
    "    try:\n",
    "        treynor = calc_treynor_ratio(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var)\n",
    "        return -treynor if np.isfinite(treynor) else np.inf\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calc_neg_treynor_ratio: {e}\")\n",
    "        return np.inf\n",
    "\n",
    "objective_dict = {\n",
    "    'max_sharpe': calc_neg_sharpe_ratio,\n",
    "    'min_variance': calc_variance,\n",
    "    'min_VaR': neg_var,\n",
    "    'min_CVaR': neg_cvar,\n",
    "    'max_treynor': calc_neg_treynor_ratio,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "def compute_performance_metrics(weights, returns, cov_matrix, rf_rate, mkt_returns, mkt_return, asset_market_cov, market_var):\n",
    "    try:\n",
    "        port_returns = returns @ weights\n",
    "        if not np.isfinite(port_returns).all():\n",
    "            print(\"Warning: Non-finite values in port_returns\")\n",
    "            port_returns = port_returns.where(np.isfinite(port_returns), 0)\n",
    "        ann_return = calc_expected_return(weights, returns)\n",
    "        ann_var = weights.T @ cov_matrix @ weights\n",
    "        ann_std = np.sqrt(ann_var) if np.isfinite(ann_var) and ann_var > 0 else np.nan\n",
    "        winning_ratio = (port_returns > 0).mean() if len(port_returns) > 0 else np.nan\n",
    "        port_skew = skew(port_returns, nan_policy='omit') if len(port_returns) > 1 else np.nan\n",
    "        port_kurt = kurtosis(port_returns, nan_policy='omit') if len(port_returns) > 1 else np.nan\n",
    "        var_5 = np.percentile(port_returns, 5) if len(port_returns) > 0 and np.isfinite(port_returns).all() else np.nan\n",
    "        cvar_5 = port_returns[port_returns <= var_5].mean() if len(port_returns[port_returns <= var_5]) > 0 else np.nan\n",
    "        tail_ratio = cvar_5 / var_5 if np.isfinite(var_5) and var_5 != 0 else np.nan\n",
    "        port_beta = calc_beta(weights, asset_market_cov, market_var)\n",
    "        port_alpha = calc_jensens_alpha(weights, returns, cov_matrix, rf_rate, mkt_return, asset_market_cov, market_var)\n",
    "        ols = sm.OLS(port_returns, sm.add_constant(mkt_returns)).fit()\n",
    "        r_squared = ols.rsquared if np.isfinite(ols.rsquared) else np.nan\n",
    "        port_sharpe = calc_sharpe_ratio(weights, returns, cov_matrix, rf_rate)\n",
    "        port_treynor = calc_treynor_ratio(weights, returns, cov_matrix, rf_rate, asset_market_cov, market_var)\n",
    "        tracking_error = np.std(port_returns - mkt_returns) if len(port_returns) > 0 else np.nan\n",
    "        info_ratio = (ann_return - mkt_return) / tracking_error if np.isfinite(tracking_error) and tracking_error != 0 else np.nan\n",
    "        downside_returns = port_returns[port_returns < 0]\n",
    "        sortino = (ann_return - rf_rate) / np.sqrt(np.mean(downside_returns**2)) if len(downside_returns) > 0 and np.isfinite(np.mean(downside_returns**2)) else np.nan\n",
    "        common_sense = ann_return / ann_std if np.isfinite(ann_std) and ann_std != 0 else np.nan\n",
    "        cum_returns = np.exp(np.cumsum(port_returns)) - 1\n",
    "        rolling_max = np.maximum.accumulate(cum_returns + 1)\n",
    "        drawdowns = (rolling_max - (cum_returns + 1)) / rolling_max\n",
    "        max_drawdown = drawdowns.max() if len(drawdowns) > 0 and np.isfinite(drawdowns).all() else np.nan\n",
    "        calmar = ann_return / max_drawdown if np.isfinite(max_drawdown) and max_drawdown != 0 else np.nan\n",
    "        gains = port_returns[port_returns > 0].sum() if len(port_returns[port_returns > 0]) > 0 else 0\n",
    "        losses = -port_returns[port_returns < 0].sum() if len(port_returns[port_returns < 0]) > 0 else 0\n",
    "        omega = gains / losses if losses != 0 else np.nan\n",
    "\n",
    "        hurst = np.nan\n",
    "        if len(port_returns) >= 16:\n",
    "            try:\n",
    "                min_block = 8\n",
    "                max_block = len(port_returns) // 2\n",
    "                block_sizes = np.unique(np.logspace(np.log10(min_block), np.log10(max_block), num=10, dtype=int))\n",
    "                rs_values = []\n",
    "                for n in block_sizes:\n",
    "                    num_blocks = len(port_returns) // n\n",
    "                    if num_blocks < 2:\n",
    "                        continue\n",
    "                    rs_block = []\n",
    "                    for i in range(num_blocks):\n",
    "                        block = port_returns[i*n:(i+1)*n]\n",
    "                        if len(block) < 2 or np.std(block, ddof=1) == 0:\n",
    "                            continue\n",
    "                        mean = np.mean(block)\n",
    "                        y = block - mean\n",
    "                        z = np.cumsum(y)\n",
    "                        r = np.max(z) - np.min(z)\n",
    "                        s = np.std(block, ddof=1)\n",
    "                        if s > 0:\n",
    "                            rs_block.append(r / s)\n",
    "                    rs_values.append(np.mean(rs_block) if rs_block else np.nan)\n",
    "                block_sizes = block_sizes[:len(rs_values)]\n",
    "                rs_values = np.array(rs_values)\n",
    "                valid_idx = ~np.isnan(rs_values) & (rs_values > 0)\n",
    "                if sum(valid_idx) >= 2:\n",
    "                    hurst = np.polyfit(np.log(block_sizes[valid_idx]), np.log(rs_values[valid_idx]), 1)[0]\n",
    "                    print(f\"R/S Hurst exponent valid points: {sum(valid_idx)}\")\n",
    "                else:\n",
    "                    print(\"Warning: Not enough valid R/S points for Hurst exponent.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error in Hurst exponent calculation: {e}\")\n",
    "\n",
    "        downside_dev = np.sqrt(np.mean(np.minimum(port_returns - rf_rate / 252, 0)**2)) if len(port_returns) > 0 else np.nan\n",
    "\n",
    "        metrics = {\n",
    "            'Annualized Return': ann_return,\n",
    "            'Annualized Variance': ann_var,\n",
    "            'Annualized Std Dev': ann_std,\n",
    "            'Winning Day Ratio': winning_ratio,\n",
    "            'Skewness': port_skew,\n",
    "            'Kurtosis': port_kurt,\n",
    "            'VaR (5%)': var_5,\n",
    "            'CVaR (5%)': cvar_5,\n",
    "            'Tail Ratio': tail_ratio,\n",
    "            'Alpha': port_alpha,\n",
    "            'Beta': port_beta,\n",
    "            'R-Squared': r_squared,\n",
    "            'Sharpe Ratio': port_sharpe,\n",
    "            'Treynor Ratio': port_treynor,\n",
    "            'Tracking Error': tracking_error,\n",
    "            'Information Ratio': info_ratio,\n",
    "            'Sortino Ratio': sortino,\n",
    "            'Common Sense Ratio': common_sense,\n",
    "            'Max Drawdown': max_drawdown,\n",
    "            'Calmar Ratio': calmar,\n",
    "            'Omega Ratio': omega,\n",
    "            'Hurst Exponent': hurst,\n",
    "            'Downside Deviation': downside_dev\n",
    "        }\n",
    "        return metrics, drawdowns\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_performance_metrics: {e}\")\n",
    "        return {}, np.array([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e35bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute baseline metrics\n",
    "initial_weights = np.array([1 / num_assets] * num_assets)\n",
    "for asset_class, target in target_exposures.items():\n",
    "    indices = asset_class_indices.get(asset_class, [])\n",
    "    if indices:\n",
    "        current_sum = sum(initial_weights[i] for i in indices)\n",
    "        if current_sum != 0:\n",
    "            scaling_factor = target / current_sum\n",
    "            for i in indices:\n",
    "                initial_weights[i] *= scaling_factor\n",
    "initial_weights = initial_weights / np.sum(initial_weights)\n",
    "np.random.seed(42)\n",
    "initial_weights_perturbed = np.random.uniform(0, 0.1, num_assets)\n",
    "for asset_class, target in target_exposures.items():\n",
    "    indices = asset_class_indices.get(asset_class, [])\n",
    "    if indices:\n",
    "        current_sum = sum(initial_weights_perturbed[i] for i in indices)\n",
    "        if current_sum != 0:\n",
    "            scaling_factor = target / current_sum\n",
    "            for i in indices:\n",
    "                initial_weights_perturbed[i] *= scaling_factor\n",
    "initial_weights_perturbed = initial_weights_perturbed / np.sum(initial_weights_perturbed)\n",
    "equal_weights = initial_weights\n",
    "equal_metrics, equal_drawdowns = compute_performance_metrics(equal_weights, log_returns_subset, port_cov_matrix, risk_free_rate, market_returns, market_return, asset_market_cov, market_var)\n",
    "print(\"\\nEqual-Weight Portfolio Metrics (Baseline):\")\n",
    "for k, v in equal_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "equal_vol = equal_metrics.get('Annualized Std Dev', np.nan)\n",
    "equal_beta = equal_metrics.get('Beta', np.nan)\n",
    "equal_var = equal_metrics.get('VaR (5%)', np.nan)\n",
    "equal_cvar = equal_metrics.get('CVaR (5%)', np.nan)\n",
    "equal_treynor = equal_metrics.get('Treynor Ratio', np.nan)\n",
    "\n",
    "safe_equal_vol = equal_vol if np.isfinite(equal_vol) else 0.2\n",
    "safe_equal_beta = equal_beta if np.isfinite(equal_beta) else 1.0\n",
    "safe_equal_var = equal_var if np.isfinite(equal_var) else -0.06\n",
    "safe_equal_cvar = equal_cvar if np.isfinite(equal_cvar) else -0.09\n",
    "safe_equal_treynor = equal_treynor if np.isfinite(equal_treynor) else 0.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints\n",
    "def safe_vol_constraint(weights, max_vol=safe_equal_vol):\n",
    "    vol = calc_standard_deviation(weights, port_cov_matrix)\n",
    "    return max_vol - vol if np.isfinite(vol) else -1e10\n",
    "\n",
    "def safe_beta_lower_constraint(weights, min_beta=0.65):\n",
    "    beta = calc_beta(weights, asset_market_cov, market_var)\n",
    "    return beta - min_beta if np.isfinite(beta) else -1e10\n",
    "\n",
    "def safe_beta_upper_constraint(weights, max_beta=1.35):\n",
    "    beta = calc_beta(weights, asset_market_cov, market_var)\n",
    "    return max_beta - beta if np.isfinite(beta) else -1e10\n",
    "\n",
    "def safe_var_constraint(weights, min_var=-0.06):\n",
    "    var = calc_var(weights, log_returns_subset)\n",
    "    return -min_var - var if np.isfinite(var) else -1e10\n",
    "\n",
    "def safe_cvar_constraint(weights, min_cvar=-0.09):\n",
    "    cvar = calc_cvar(weights, log_returns_subset)\n",
    "    return -min_cvar - cvar if np.isfinite(cvar) else -1e10\n",
    "\n",
    "def safe_treynor_constraint(weights, min_treynor=0.03):\n",
    "    treynor = calc_treynor_ratio(weights, log_returns_subset, port_cov_matrix, risk_free_rate, asset_market_cov, market_var)\n",
    "    return treynor - min_treynor if np.isfinite(treynor) else -1e10\n",
    "\n",
    "def safe_asset_class_constraint(weights, positions, target_weight):\n",
    "    return sum(weights[i] for i in positions) - target_weight\n",
    "\n",
    "constraint_sets = {\n",
    "    'constraint1': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "    ],\n",
    "    'constraint2': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "        {'type': 'ineq', 'fun': safe_vol_constraint},\n",
    "    ],\n",
    "    'constraint3': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "        {'type': 'ineq', 'fun': safe_vol_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_beta_lower_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_beta_upper_constraint},\n",
    "    ],\n",
    "    'constraint4': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "        {'type': 'ineq', 'fun': safe_vol_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_beta_lower_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_beta_upper_constraint},\n",
    "    ],\n",
    "    'constraint5': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "        {'type': 'ineq', 'fun': safe_vol_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_var_constraint},\n",
    "    ],\n",
    "    'constraint6': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "        {'type': 'ineq', 'fun': safe_vol_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_cvar_constraint},\n",
    "    ],\n",
    "    'constraint7': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "        {'type': 'ineq', 'fun': safe_vol_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_treynor_constraint},\n",
    "    ],\n",
    "    'constraint8': [\n",
    "        {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "        {'type': 'ineq', 'fun': safe_vol_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_beta_lower_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_beta_upper_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_var_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_cvar_constraint},\n",
    "        {'type': 'ineq', 'fun': safe_treynor_constraint},\n",
    "    ],\n",
    "}\n",
    "\n",
    "for set_name in constraint_sets:\n",
    "    for asset_class, positions in asset_class_indices.items():\n",
    "        target_weight = target_exposures[asset_class]\n",
    "        constraint_sets[set_name].append(\n",
    "            {'type': 'eq', 'fun': lambda w, pos=positions, tw=target_weight: safe_asset_class_constraint(w, pos, tw)}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "bounds = [(0.0, 0.2) for _ in range(num_assets)]\n",
    "selected_objective = 'max_sharpe'  # Options: 'max_sharpe', 'min_variance', 'min_VaR', 'min_CVaR', 'max_treynor'\n",
    "selected_constraint = 'constraint8'\n",
    "objective_fun = objective_dict.get(selected_objective, calc_neg_sharpe_ratio)\n",
    "constraints = constraint_sets.get(selected_constraint, constraint_sets['constraint1'])\n",
    "print(f\"\\nOptimizing for {selected_objective} with {selected_constraint}\")\n",
    "\n",
    "try:\n",
    "    optimized_results = minimize(\n",
    "        objective_fun,\n",
    "        initial_weights_perturbed,\n",
    "        args=(log_returns_subset, port_cov_matrix, risk_free_rate, asset_market_cov, market_var),\n",
    "        method='SLSQP',\n",
    "        constraints=constraints,\n",
    "        bounds=bounds,\n",
    "        options={'disp': True, 'maxiter': 2000, 'ftol': 1e-9, 'eps': 1e-8}\n",
    "    )\n",
    "    if not optimized_results.success:\n",
    "        print(f\"Warning: Optimization for {selected_objective} with {selected_constraint} failed: {optimized_results.message}\")\n",
    "        print(\"Falling back to constraint1\")\n",
    "        constraints = constraint_sets['constraint1']\n",
    "        optimized_results = minimize(\n",
    "            objective_fun,\n",
    "            initial_weights_perturbed,\n",
    "            args=(log_returns_subset, port_cov_matrix, risk_free_rate, asset_market_cov, market_var),\n",
    "            method='SLSQP',\n",
    "            constraints=constraints,\n",
    "            bounds=bounds,\n",
    "            options={'disp': True, 'maxiter': 2000, 'ftol': 1e-9, 'eps': 1e-8}\n",
    "        )\n",
    "        if not optimized_results.success:\n",
    "            print(f\"Warning: Fallback optimization with constraint1 failed: {optimized_results.message}\")\n",
    "            optimal_weights = initial_weights\n",
    "        else:\n",
    "            optimal_weights = optimized_results.x\n",
    "            print(f\"Fallback optimization with constraint1 successful, objective value: {optimized_results.fun:.4f}\")\n",
    "    else:\n",
    "        optimal_weights = optimized_results.x\n",
    "        print(f\"Optimization for {selected_objective} with {selected_constraint} successful, objective value: {optimized_results.fun:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in optimization for {selected_objective} with {selected_constraint}: {e}\")\n",
    "    optimal_weights = initial_weights\n",
    "\n",
    "# Verify constraints\n",
    "print(\"\\nVerifying Optimal Portfolio Constraints:\")\n",
    "try:\n",
    "    opt_vol = calc_standard_deviation(optimal_weights, port_cov_matrix)\n",
    "    opt_beta = calc_beta(optimal_weights, asset_market_cov, market_var)\n",
    "    opt_var = calc_var(optimal_weights, log_returns_subset)\n",
    "    opt_cvar = calc_cvar(optimal_weights, log_returns_subset)\n",
    "    opt_treynor = calc_treynor_ratio(optimal_weights, log_returns_subset, port_cov_matrix, risk_free_rate, asset_market_cov, market_var)\n",
    "    print(f\"Optimal volatility: {opt_vol:.4f} (should be <= {safe_equal_vol:.4f})\")\n",
    "    print(f\"Optimal VaR (5%): {opt_var:.4f} (should be >= -0.06 for constraint5, constraint8)\")\n",
    "    print(f\"Optimal CVaR (5%): {opt_cvar:.4f} (should be >= -0.09 for constraint6, constraint8)\")\n",
    "    print(f\"Optimal Treynor Ratio: {opt_treynor:.4f} (should be >= 0.03 for constraint7, constraint8)\")\n",
    "    for asset_class, positions in asset_class_indices.items():\n",
    "        asset_class_weight = sum(optimal_weights[i] for i in positions)\n",
    "        target_weight = target_exposures[asset_class]\n",
    "        print(f\"{asset_class} weight: {asset_class_weight:.4f} (should be = {target_weight:.4f})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in verifying constraints: {e}\")\n",
    "\n",
    "# Optimal portfolio metrics\n",
    "try:\n",
    "    opt_return = calc_expected_return(optimal_weights, log_returns_subset)\n",
    "    opt_vol = calc_standard_deviation(optimal_weights, port_cov_matrix)\n",
    "    opt_sharpe = calc_sharpe_ratio(optimal_weights, log_returns_subset, port_cov_matrix, risk_free_rate)\n",
    "    opt_beta = calc_beta(optimal_weights, asset_market_cov, market_var)\n",
    "    opt_treynor = calc_treynor_ratio(optimal_weights, log_returns_subset, port_cov_matrix, risk_free_rate, asset_market_cov, market_var)\n",
    "    opt_alpha = calc_jensens_alpha(optimal_weights, log_returns_subset, port_cov_matrix, risk_free_rate, market_return, asset_market_cov, market_var)\n",
    "\n",
    "    print(\"\\nOptimal Weights:\")\n",
    "    for ticker, weight in zip(log_returns_subset.columns, optimal_weights):\n",
    "        print(f\"{ticker}: {weight:.4f}\")\n",
    "    print(f\"Expected Annual Return: {opt_return:.4f}\")\n",
    "    print(f\"Expected Volatility: {opt_vol:.4f}\")\n",
    "    print(f\"Sharpe Ratio: {opt_sharpe:.4f}\")\n",
    "    print(f\"Treynor Ratio: {opt_treynor:.4f}\")\n",
    "    print(f\"Jensen's Alpha: {opt_alpha:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in computing optimal portfolio metrics: {e}\")\n",
    "\n",
    "optimal_metrics, optimal_drawdowns = compute_performance_metrics(\n",
    "    optimal_weights, log_returns_subset, port_cov_matrix, risk_free_rate,\n",
    "    market_returns, market_return, asset_market_cov, market_var\n",
    ")\n",
    "print(\"\\nOptimal Portfolio Metrics:\")\n",
    "for k, v in optimal_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9721514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis for risk-free rate (only for max_sharpe and max_treynor)\n",
    "sensitivity_results = []\n",
    "if selected_objective in ['max_sharpe', 'max_treynor']:\n",
    "    risk_free_rates = [0.04, 0.0696, 0.10]\n",
    "    print(\"\\nPerforming Risk-Free Rate Sensitivity Analysis (for max_sharpe or max_treynor):\")\n",
    "    for rf in risk_free_rates:\n",
    "        try:\n",
    "            opt_res = minimize(\n",
    "                objective_fun,\n",
    "                initial_weights_perturbed,\n",
    "                args=(log_returns_subset, port_cov_matrix, rf, asset_market_cov, market_var),\n",
    "                method='SLSQP',\n",
    "                constraints=constraints,\n",
    "                bounds=bounds,\n",
    "                options={'disp': True, 'maxiter': 2000, 'ftol': 1e-9, 'eps': 1e-8}\n",
    "            )\n",
    "            if opt_res.success:\n",
    "                opt_return = calc_expected_return(opt_res.x, log_returns_subset)\n",
    "                opt_vol = calc_standard_deviation(opt_res.x, port_cov_matrix)\n",
    "                opt_beta = calc_beta(opt_res.x, asset_market_cov, market_var)\n",
    "                opt_var = calc_var(opt_res.x, log_returns_subset)\n",
    "                opt_cvar = calc_cvar(opt_res.x, log_returns_subset)\n",
    "                opt_treynor = calc_treynor_ratio(opt_res.x, log_returns_subset, port_cov_matrix, rf, asset_market_cov, market_var)\n",
    "                sensitivity_results.append((rf, opt_return, opt_vol, opt_beta, opt_var, opt_cvar, opt_treynor))\n",
    "                print(f\"Risk-Free Rate {rf:.4f} optimization successful, objective value: {opt_res.fun:.4f}\")\n",
    "            else:\n",
    "                print(f\"Warning: Sensitivity analysis for risk-free rate {rf:.4f} failed: {opt_res.message}\")\n",
    "                sensitivity_results.append((rf, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sensitivity analysis for risk-free rate {rf:.4f}: {e}\")\n",
    "            sensitivity_results.append((rf, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan))\n",
    "    print(\"\\nRisk-Free Rate Sensitivity Analysis Results:\")\n",
    "    for rf, ret, vol, beta, var, cvar, treynor in sensitivity_results:\n",
    "        print(f\"Risk-Free Rate: {rf:.4f}, Return: {ret:.4f}, Volatility: {vol:.4f}, Beta: {beta:.4f}, VaR: {var:.4f}, CVaR: {cvar:.4f}, Treynor: {treynor:.4f}\")\n",
    "else:\n",
    "    print(\"\\nSkipping Risk-Free Rate Sensitivity Analysis (not applicable for selected objective)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359371c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute optimal_port_returns\n",
    "try:\n",
    "    optimal_port_returns = log_returns_subset @ optimal_weights\n",
    "    if not np.isfinite(optimal_port_returns).all():\n",
    "        print(\"Warning: Non-finite values in optimal_port_returns, replacing with 0\")\n",
    "        optimal_port_returns = optimal_port_returns.where(np.isfinite(optimal_port_returns), 0)\n",
    "except Exception as e:\n",
    "    print(f\"Error in computing optimal_port_returns: {e}\")\n",
    "    optimal_port_returns = pd.Series(0, index=log_returns_subset.index)\n",
    "\n",
    "# Statistical Tests\n",
    "try:\n",
    "    equal_port_returns = log_returns_subset @ equal_weights\n",
    "    if len(optimal_port_returns) != len(equal_port_returns) or len(optimal_port_returns) != len(market_returns):\n",
    "        print(\"Warning: Mismatched lengths for statistical tests\")\n",
    "    else:\n",
    "        _, p_val_norm_opt = shapiro(optimal_port_returns)\n",
    "        _, p_val_norm_eq = shapiro(equal_port_returns)\n",
    "        print(f\"\\nNormality Test (Shapiro-Wilk): Optimal p={p_val_norm_opt:.4f}, Equal-Weight p={p_val_norm_eq:.4f}\")\n",
    "        if not np.allclose(optimal_port_returns, equal_port_returns):\n",
    "            t_stat, p_val = ttest_rel(optimal_port_returns, equal_port_returns)\n",
    "            print(f\"Paired t-test (Optimal vs Equal-Weight): T={t_stat:.4f}, p={p_val:.4f}\")\n",
    "            wilcoxon_stat, p_val_w = wilcoxon(optimal_port_returns, equal_port_returns, zero_method='zsplit')\n",
    "            print(f\"Wilcoxon Test (Optimal vs Equal-Weight): Stat={wilcoxon_stat:.4f}, p={p_val_w:.4f}\")\n",
    "        else:\n",
    "            print(\"Skipping paired t-test and Wilcoxon test: Optimal and Equal-Weight portfolios are identical\")\n",
    "        f_stat, p_val_f = f_oneway(optimal_port_returns, equal_port_returns, market_returns)\n",
    "        print(f\"F-test (Optimal vs Equal-Weight vs Market): F={f_stat:.4f}, p={p_val_f:.4f}\")\n",
    "        t_stat_market, p_val_market = ttest_ind(optimal_port_returns, market_returns)\n",
    "        print(f\"Independent t-test (Optimal vs Market): T={t_stat_market:.4f}, p={p_val_market:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in statistical tests: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5663d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Rebalancing with Transaction Costs\n",
    "transaction_cost = 0.001\n",
    "rebal_period = 252\n",
    "rebal_weights = equal_weights.copy()\n",
    "rebal_port_returns = pd.Series(index=log_returns_subset.index, dtype=float)\n",
    "total_transaction_costs = 0\n",
    "previous_weights = rebal_weights.copy()\n",
    "print(\"\\nRebalancing Diagnostics:\")\n",
    "for i in range(0, len(log_returns_subset), rebal_period):\n",
    "    period_returns = log_returns_subset.iloc[i:i+rebal_period]\n",
    "    period_index = period_returns.index\n",
    "    print(f\"Period {i//rebal_period + 1}: {period_index[0]} to {period_index[-1] if len(period_index) > 1 else period_index[0]}, Length: {len(period_returns)}\")\n",
    "    if len(period_returns) >= 30:\n",
    "        try:\n",
    "            period_cov = LedoitWolf().fit(period_returns).covariance_ * 252\n",
    "            cond_number = np.linalg.cond(period_cov)\n",
    "            if cond_number > 1e6:\n",
    "                print(\"  Warning: High condition number, applying regularization\")\n",
    "                period_cov += np.eye(period_cov.shape[0]) * 1e-4\n",
    "            if not np.any(np.isnan(period_cov)):\n",
    "                rebal_constraints = [\n",
    "                    {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "                    {'type': 'ineq', 'fun': lambda weights: safe_vol_constraint(weights, max_vol=safe_equal_vol * 1.1)},\n",
    "                ]\n",
    "                for asset_class, positions in asset_class_indices.items():\n",
    "                    target_weight = target_exposures[asset_class]\n",
    "                    rebal_constraints.append(\n",
    "                        {'type': 'eq', 'fun': lambda w, pos=positions, tw=target_weight: safe_asset_class_constraint(w, pos, tw)}\n",
    "                    )\n",
    "                opt_res = minimize(\n",
    "                    objective_fun,\n",
    "                    rebal_weights,\n",
    "                    args=(period_returns, period_cov, risk_free_rate, asset_market_cov, market_var),\n",
    "                    method='SLSQP',\n",
    "                    constraints=rebal_constraints,\n",
    "                    bounds=bounds,\n",
    "                    options={'disp': False, 'maxiter': 2000, 'ftol': 1e-9, 'eps': 1e-8}\n",
    "                )\n",
    "                if opt_res.success:\n",
    "                    new_weights = opt_res.x\n",
    "                    weight_changes = np.abs(new_weights - previous_weights)\n",
    "                    period_transaction_cost = transaction_cost * weight_changes.sum()\n",
    "                    total_transaction_costs += period_transaction_cost\n",
    "                    rebal_weights = new_weights\n",
    "                    previous_weights = rebal_weights.copy()\n",
    "                    print(f\"  Optimization successful, new weights sum: {np.sum(rebal_weights):.4f}, Transaction cost: {period_transaction_cost:.6f}\")\n",
    "                else:\n",
    "                    print(f\"  Optimization failed: {opt_res.message}, using previous weights\")\n",
    "                    rebal_weights = previous_weights\n",
    "            else:\n",
    "                print(\"  Invalid covariance matrix, using previous weights\")\n",
    "                rebal_weights = previous_weights\n",
    "        except Exception as e:\n",
    "            print(f\"  Error in rebalancing optimization: {e}, using previous weights\")\n",
    "            rebal_weights = previous_weights\n",
    "    else:\n",
    "        print(\"  Insufficient data, using previous weights\")\n",
    "        rebal_weights = previous_weights\n",
    "    period_port_returns = period_returns @ rebal_weights\n",
    "    if i > 0 and 'period_transaction_cost' in locals() and period_transaction_cost > 0:\n",
    "        period_port_returns.iloc[0] -= period_transaction_cost\n",
    "    rebal_port_returns[period_index] = period_port_returns\n",
    "    drift = np.sum(np.abs(rebal_weights - initial_weights))\n",
    "    print(f\"  Portfolio drift from initial weights: {drift:.4f}\")\n",
    "\n",
    "print(\"Length of rebal_port_returns:\", len(rebal_port_returns))\n",
    "print(\"Any NaN in rebal_port_returns?\", rebal_port_returns.isna().sum())\n",
    "print(f\"Total Transaction Costs: {total_transaction_costs:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Weights\n",
    "try:\n",
    "    non_zero_indices = optimal_weights > 1e-6\n",
    "    non_zero_weights = optimal_weights[non_zero_indices]\n",
    "    non_zero_labels = log_returns_subset.columns[non_zero_indices]\n",
    "    sorted_indices = np.argsort(non_zero_weights)[::-1]\n",
    "    sorted_weights = non_zero_weights[sorted_indices]\n",
    "    sorted_labels = non_zero_labels[sorted_indices]\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(sorted_labels)), sorted_weights)\n",
    "    plt.xlabel('Assets', fontsize=12)\n",
    "    plt.ylabel('Weights', fontsize=12)\n",
    "    plt.title(f'Optimal Portfolio Weights for {selected_objective} with {selected_constraint} (Non-Zero, Sorted Descending)', fontsize=14)\n",
    "    plt.xticks(range(len(sorted_labels)), sorted_labels, rotation=45, ha='right')\n",
    "    for bar, weight in zip(bars, sorted_weights):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{weight:.3f}',\n",
    "                 ha='center', va='bottom')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(sorted_weights, labels=sorted_labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(f'Optimal Portfolio Weights for {selected_objective} with {selected_constraint} (Pie Chart, Non-Zero, Sorted Descending)', fontsize=14)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error in weights visualization: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476981be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Efficient Frontier\n",
    "try:\n",
    "    returns_range = np.linspace(0, 0.5, 50)\n",
    "    volatilities = []\n",
    "    for ret in returns_range:\n",
    "        constraints = [\n",
    "            {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "            {'type': 'eq', 'fun': lambda weights: calc_expected_return(weights, log_returns_subset) - ret}\n",
    "        ]\n",
    "        for asset_class, positions in asset_class_indices.items():\n",
    "            target_weight = target_exposures[asset_class]\n",
    "            constraints.append(\n",
    "                {'type': 'eq', 'fun': lambda w, pos=positions, tw=target_weight: safe_asset_class_constraint(w, pos, tw)}\n",
    "            )\n",
    "        opt_res = minimize(\n",
    "            calc_standard_deviation,\n",
    "            initial_weights_perturbed,\n",
    "            args=(port_cov_matrix,),\n",
    "            method='SLSQP',\n",
    "            constraints=constraints,\n",
    "            bounds=bounds,\n",
    "            options={'maxiter': 2000, 'ftol': 1e-9, 'eps': 1e-8}\n",
    "        )\n",
    "        volatilities.append(opt_res.fun if opt_res.success else np.nan)\n",
    "\n",
    "    valid_idx = ~np.isnan(volatilities)\n",
    "    returns_range = returns_range[valid_idx]\n",
    "    volatilities = np.array(volatilities)[valid_idx]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(volatilities, returns_range, label='Efficient Frontier', color='blue', alpha=0.6)\n",
    "    plt.scatter(opt_vol, opt_return, color='red', marker='*', s=200, label='Optimal Portfolio')\n",
    "    plt.xlabel('Volatility', fontsize=12)\n",
    "    plt.ylabel('Expected Return', fontsize=12)\n",
    "    plt.title(f'Efficient Frontier for {selected_objective} with {selected_constraint}', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error in efficient frontier visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab599d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Correlation Heatmap\n",
    "try:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(log_returns_subset.corr(), annot=False, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap of Asset Returns', fontsize=14)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error in correlation heatmap: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba293943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Returns Distribution\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(optimal_port_returns, bins=50, alpha=0.7, label='Optimal Portfolio')\n",
    "    plt.hist(market_returns, bins=50, alpha=0.7, label='Market (Sensex)')\n",
    "    plt.xlabel('Daily Returns', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title(f'Returns Distribution for {selected_objective} with {selected_constraint}', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error in returns distribution visualization: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Rebalanced vs Static Portfolio Cumulative Returns\n",
    "try:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(log_returns_subset.index, np.exp(np.cumsum(optimal_port_returns)) - 1, label='Static Optimal')\n",
    "    plt.plot(rebal_port_returns.index, np.exp(np.cumsum(rebal_port_returns.dropna())) - 1, label='Rebalanced')\n",
    "    plt.plot(market_returns.index, np.exp(np.cumsum(market_returns)) - 1, label='Market (Sensex)')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Cumulative Returns', fontsize=12)\n",
    "    plt.title(f'Cumulative Returns: Rebalanced vs Static vs Market for {selected_objective} with {selected_constraint}', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(YearLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error in cumulative returns visualization: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a198135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Drawdown Plot\n",
    "try:\n",
    "    cum_returns = np.exp(np.cumsum(optimal_port_returns)) - 1\n",
    "    rolling_max = np.maximum.accumulate(cum_returns + 1)\n",
    "    drawdowns = (rolling_max - (cum_returns + 1)) / rolling_max\n",
    "    max_dd = drawdowns.max() if np.isfinite(drawdowns).all() else np.nan\n",
    "    t_stat_dd, p_val_dd = ttest_1samp(drawdowns, 0) if np.isfinite(drawdowns).all() else (np.nan, np.nan)\n",
    "    print(f\"\\nMax Drawdown: {max_dd:.4f}\")\n",
    "    print(f\"Drawdown t-test: T={t_stat_dd:.4f}, p={p_val_dd:.4f}\")\n",
    "\n",
    "    drawdowns_series = pd.Series(drawdowns, index=optimal_port_returns.index)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(drawdowns_series, label='Drawdowns', color='red')\n",
    "    plt.axhline(y=max_dd, color='black', linestyle='dashed', label=f'Max Drawdown: {max_dd:.4f}')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Drawdown', fontsize=12)\n",
    "    plt.title(f'Drawdowns of Optimal Portfolio for {selected_objective} with {selected_constraint}', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_locator(YearLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error in drawdown visualization: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation\n",
    "try:\n",
    "    num_simulations = [500, 1000, 2000]\n",
    "    for n_sim in num_simulations:\n",
    "        df_t = 3\n",
    "        sim_returns = t.rvs(df_t, loc=log_returns_subset.mean() * 252, scale=np.sqrt(np.diag(port_cov_matrix)), size=(n_sim, num_assets))\n",
    "        sim_port_returns = sim_returns @ optimal_weights\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(sim_port_returns, bins=50, alpha=0.7, label=f'Monte Carlo (n={n_sim})')\n",
    "        plt.axvline(opt_return, color='red', linestyle='dashed', label=f'Expected Return: {opt_return:.4f}')\n",
    "        plt.xlabel('Annualized Return', fontsize=12)\n",
    "        plt.ylabel('Frequency', fontsize=12)\n",
    "        plt.title(f'Monte Carlo Simulation of Portfolio Returns (n={n_sim}) for {selected_objective} with {selected_constraint}', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"Monte Carlo (n={n_sim}) Mean Return: {np.mean(sim_port_returns):.4f}, Std: {np.std(sim_port_returns):.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in Monte Carlo simulation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress Testing\n",
    "try:\n",
    "    print(\"\\nStress Testing:\")\n",
    "    scenarios = {\n",
    "        'Severe Market Crash': {'shock': -0.50, 'type': 'return'},\n",
    "        'Mild Recession': {'shock': -0.15, 'type': 'return'},\n",
    "        'Economic Boom': {'shock': 0.20, 'type': 'return'},\n",
    "        'Increased Volatility': {'shock': 2.0, 'type': 'vol'},\n",
    "    }\n",
    "\n",
    "    stress_results = {}\n",
    "    for name, params in scenarios.items():\n",
    "        if params['type'] == 'return':\n",
    "            shock = params['shock']\n",
    "            stressed_port_return = opt_return + opt_beta * shock\n",
    "            stress_results[name] = stressed_port_return\n",
    "            print(f\"{name}: Stressed Annual Return: {stressed_port_return:.4f}\")\n",
    "        elif params['type'] == 'vol':\n",
    "            shock = params['shock']\n",
    "            stressed_vol = opt_vol * shock\n",
    "            stressed_sharpe = (opt_return - risk_free_rate) / stressed_vol if np.isfinite(stressed_vol) and stressed_vol != 0 else np.nan\n",
    "            stress_results[name] = (stressed_vol, stressed_sharpe)\n",
    "            print(f\"{name}: Stressed Volatility: {stressed_vol:.4f}, Stressed Sharpe: {stressed_sharpe:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in stress testing: {e}\")\n",
    "\n",
    "# Stress Monte Carlo\n",
    "try:\n",
    "    stress_mean = log_returns_subset.mean() * 252 - 0.10\n",
    "    stress_cov = port_cov_matrix * 4\n",
    "    stressed_sim_returns = np.random.multivariate_normal(stress_mean, stress_cov, num_simulations[-1])\n",
    "    stressed_port_returns = stressed_sim_returns @ optimal_weights\n",
    "    mean_stressed_return = np.mean(stressed_port_returns)\n",
    "    var_stressed = np.percentile(stressed_port_returns, 5) if np.isfinite(stressed_port_returns).all() else np.nan\n",
    "    print(f\"Stressed Monte Carlo Mean Return: {mean_stressed_return:.4f}\")\n",
    "    print(f\"Stressed VaR (5%): {var_stressed:.4f}\")\n",
    "\n",
    "    simulated_port_returns = np.random.multivariate_normal(log_returns_subset.mean() * 252, port_cov_matrix, num_simulations[-1]) @ optimal_weights\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(simulated_port_returns, bins=50, alpha=0.7, label='Normal')\n",
    "    plt.hist(stressed_port_returns, bins=50, alpha=0.7, label='Stressed', color='red')\n",
    "    plt.axvline(opt_return, color='blue', linestyle='dashed', label='Normal Expected')\n",
    "    plt.axvline(mean_stressed_return, color='black', linestyle='dashed', label='Stressed Expected')\n",
    "    plt.xlabel('Annualized Return', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title(f'Normal vs Stressed Monte Carlo Simulations for {selected_objective} with {selected_constraint}', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    t_stat_stress, p_val_stress = ttest_ind(simulated_port_returns, stressed_port_returns)\n",
    "    print(f\"t-test Normal vs Stressed Returns: T={t_stat_stress:.4f}, p={p_val_stress:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in stress Monte Carlo: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac59605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting\n",
    "def check_stationarity(series):\n",
    "    try:\n",
    "        result = adfuller(series.dropna(), autolag='AIC')\n",
    "        print(f\"ADF Statistic: {result[0]:.4f}, p-value: {result[1]:.4f}\")\n",
    "        return result[1] < 0.05\n",
    "    except Exception as e:\n",
    "        print(f\"Error in stationarity check: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_lagged_features(series, lags=5):\n",
    "    try:\n",
    "        df = pd.DataFrame(series, columns=['returns'])\n",
    "        for i in range(1, lags + 1):\n",
    "            df[f'lag_{i}'] = series.shift(i)\n",
    "        return df.dropna()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in create_lagged_features: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def evaluate_forecast(test, forecast, model_name, train, rmse):\n",
    "    try:\n",
    "        forecast = pd.Series(forecast, index=test.index, name='forecast')\n",
    "        print(f\"\\n{model_name} Forecast Diagnostics:\")\n",
    "        print(\"NaN in forecast:\", np.isnan(forecast).sum())\n",
    "        print(\"Inf in forecast:\", np.isinf(forecast).sum())\n",
    "        print(\"Forecast index first/last:\", forecast.index[0], forecast.index[-1])\n",
    "        print(\"Index match with test?\", forecast.index.equals(test.index))\n",
    "        print(\"Forecast first 5 values:\", forecast[:5].values)\n",
    "\n",
    "        if not forecast.index.equals(test.index):\n",
    "            print(f\"Warning: Index mismatch in {model_name}. Reindexing forecast.\")\n",
    "            forecast = forecast.reindex(test.index, method='nearest')\n",
    "\n",
    "        forecast_errors = forecast - test\n",
    "        print(\"NaN in forecast_errors:\", forecast_errors.isna().sum())\n",
    "        print(\"Inf in forecast_errors:\", np.isinf(forecast_errors).sum())\n",
    "        print(\"Forecast_errors first 5 values:\", forecast_errors.head().values)\n",
    "        print(f\"{model_name} RMSE: {rmse:.4f}\")\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(train.index, train, label='Train')\n",
    "        plt.plot(test.index, test, label='Test')\n",
    "        plt.plot(test.index, forecast, label=f'{model_name} Forecast', linestyle='--')\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('Portfolio Returns', fontsize=12)\n",
    "        plt.title(f'Portfolio Returns Forecast with {model_name}', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.gca().xaxis.set_major_locator(YearLocator())\n",
    "        plt.gca().xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        valid_errors = forecast_errors.dropna()\n",
    "        if len(valid_errors) > 0 and np.all(np.isfinite(valid_errors)):\n",
    "            t_stat, p_val = ttest_1samp(valid_errors, 0)\n",
    "            print(f\"{model_name} Forecast t-test: T={t_stat:.4f}, p={p_val:.4f}\")\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(valid_errors, bins=30, alpha=0.7, edgecolor='black', label=f'{model_name} Forecast Errors')\n",
    "            plt.axvline(0, color='red', linestyle='dashed', label='Zero Error')\n",
    "            plt.xlabel('Forecast Error', fontsize=12)\n",
    "            plt.ylabel('Frequency', fontsize=12)\n",
    "            plt.title(f'Distribution of {model_name} Forecast Errors', fontsize=14)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Warning: Cannot perform t-test for {model_name}. Valid errors length: {len(valid_errors)}\")\n",
    "        return forecast, valid_errors\n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluate_forecast for {model_name}: {e}\")\n",
    "        return pd.Series(), pd.Series()\n",
    "\n",
    "# Forecasting Setup\n",
    "try:\n",
    "    port_returns_ts = pd.Series(optimal_port_returns, index=log_returns.index[:len(optimal_port_returns)])\n",
    "    print(\"\\nForecasting Diagnostics:\")\n",
    "    print(\"Length of port_returns_ts:\", len(port_returns_ts))\n",
    "    print(\"NaN in port_returns_ts:\", port_returns_ts.isna().sum())\n",
    "    print(\"Inf in port_returns_ts:\", np.isinf(port_returns_ts).sum())\n",
    "    print(\"Std of port_returns_ts:\", port_returns_ts.std())\n",
    "\n",
    "    stationary = check_stationarity(port_returns_ts)\n",
    "    if not stationary:\n",
    "        print(\"Series is non-stationary. Applying first differencing.\")\n",
    "        port_returns_ts_diff = port_returns_ts.diff().dropna()\n",
    "        print(\"Stationarity check on differenced series:\")\n",
    "        stationary = check_stationarity(port_returns_ts_diff)\n",
    "        if stationary:\n",
    "            port_returns_ts = port_returns_ts_diff\n",
    "            print(\"Using differenced series for forecasting.\")\n",
    "        else:\n",
    "            print(\"Warning: Differenced series is still non-stationary. Proceed with caution.\")\n",
    "\n",
    "    port_returns_ts = port_returns_ts.dropna()\n",
    "    train_size = int(len(port_returns_ts) * 0.8)\n",
    "    train = port_returns_ts[:train_size]\n",
    "    test = port_returns_ts[train_size:]\n",
    "    print(\"Train length:\", len(train))\n",
    "    print(\"Test length:\", len(test))\n",
    "    print(\"Train index first/last:\", train.index[0], train.index[-1])\n",
    "    print(\"Test index first/last:\", test.index[0], test.index[-1])\n",
    "    print(\"Train first 5 values:\", train.head().values)\n",
    "    print(\"Test first 5 values:\", test.head().values)\n",
    "\n",
    "    forecasts = {}\n",
    "    valid_errors_dict = {}\n",
    "\n",
    "    # Baseline: Moving Average\n",
    "    ma_window = 20\n",
    "    forecast_ma = train.rolling(window=ma_window).mean().iloc[-1]\n",
    "    forecast_ma = pd.Series([forecast_ma] * len(test), index=test.index)\n",
    "    rmse_ma = np.sqrt(mean_squared_error(test, forecast_ma)) if np.isfinite(test).all() and np.isfinite(forecast_ma).all() else np.nan\n",
    "    forecast_ma, errors_ma = evaluate_forecast(test, forecast_ma, \"Moving Average\", train, rmse_ma)\n",
    "    forecasts['Moving Average'] = forecast_ma\n",
    "    valid_errors_dict['Moving Average'] = errors_ma\n",
    "\n",
    "    # ARIMA\n",
    "    try:\n",
    "        model_arima = ARIMA(train.values, order=(1,0,0) if stationary else (1,1,1), trend='c', enforce_stationarity=True, enforce_invertibility=True)\n",
    "        result_arima = model_arima.fit(method_kwargs={'maxiter': 200})\n",
    "        forecast_arima = result_arima.get_forecast(steps=len(test)).predicted_mean\n",
    "        forecast_arima = pd.Series(forecast_arima, index=test.index)\n",
    "        if np.any(np.isnan(forecast_arima)) or np.any(np.isinf(forecast_arima)):\n",
    "            print(\"Warning: ARIMA forecast contains NaN or Inf. Using moving average.\")\n",
    "            forecast_arima = forecast_ma\n",
    "        else:\n",
    "            rmse_arima = np.sqrt(mean_squared_error(test, forecast_arima)) if np.isfinite(test).all() and np.isfinite(forecast_arima).all() else np.nan\n",
    "            forecast_arima, errors_arima = evaluate_forecast(test, forecast_arima, \"ARIMA\", train, rmse_arima)\n",
    "            forecasts['ARIMA'] = forecast_arima\n",
    "            valid_errors_dict['ARIMA'] = errors_arima\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ARIMA fitting: {e}\")\n",
    "        print(\"Using moving average as fallback for ARIMA\")\n",
    "        forecast_arima = forecast_ma\n",
    "        rmse_arima = rmse_ma\n",
    "        forecast_arima, errors_arima = evaluate_forecast(test, forecast_arima, \"ARIMA\", train, rmse_arima)\n",
    "        forecasts['ARIMA'] = forecast_arima\n",
    "        valid_errors_dict['ARIMA'] = errors_arima\n",
    "\n",
    "    # Auto-ARIMA\n",
    "    if PMDARIMA_AVAILABLE:\n",
    "        try:\n",
    "            model_auto_arima = auto_arima(\n",
    "                train.values,\n",
    "                seasonal=False,\n",
    "                suppress_warnings=True,\n",
    "                maxiter=200,\n",
    "                start_p=0,\n",
    "                start_q=0,\n",
    "                max_p=3,\n",
    "                max_q=3,\n",
    "                max_d=3,\n",
    "                method='nm',\n",
    "                error_action='ignore',\n",
    "                trace=True\n",
    "            )\n",
    "            forecast_auto_arima = model_auto_arima.predict(n_periods=len(test))\n",
    "            forecast_auto_arima = pd.Series(forecast_auto_arima, index=test.index)\n",
    "            if np.any(np.isnan(forecast_auto_arima)) or np.any(np.isinf(forecast_auto_arima)):\n",
    "                print(\"Warning: Auto-ARIMA forecast contains NaN or Inf. Using moving average.\")\n",
    "                forecast_auto_arima = forecast_ma\n",
    "            else:\n",
    "                rmse_auto_arima = np.sqrt(mean_squared_error(test, forecast_auto_arima)) if np.isfinite(test).all() and np.isfinite(forecast_auto_arima).all() else np.nan\n",
    "                forecast_auto_arima, errors_auto_arima = evaluate_forecast(test, forecast_auto_arima, \"Auto-ARIMA\", train, rmse_auto_arima)\n",
    "                forecasts['Auto-ARIMA'] = forecast_auto_arima\n",
    "                valid_errors_dict['Auto-ARIMA'] = errors_auto_arima\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Auto-ARIMA fitting: {e}\")\n",
    "            print(\"Using moving average as fallback for Auto-ARIMA\")\n",
    "            forecast_auto_arima = forecast_ma\n",
    "            rmse_auto_arima = rmse_ma\n",
    "            forecast_auto_arima, errors_auto_arima = evaluate_forecast(test, forecast_auto_arima, \"Auto-ARIMA\", train, rmse_auto_arima)\n",
    "            forecasts['Auto-ARIMA'] = forecast_auto_arima\n",
    "            valid_errors_dict['Auto-ARIMA'] = errors_auto_arima\n",
    "    else:\n",
    "        print(\"Auto-ARIMA skipped (pmdarima not available). Using ARIMA as fallback.\")\n",
    "        forecasts['Auto-ARIMA'] = forecast_arima\n",
    "        valid_errors_dict['Auto-ARIMA'] = errors_arima\n",
    "\n",
    "    # XGBoost\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        try:\n",
    "            lags = 5\n",
    "            train_lagged = create_lagged_features(port_returns_ts, lags)\n",
    "            train_lagged = train_lagged[train_lagged.index <= train.index[-1]]\n",
    "            test_lagged = create_lagged_features(port_returns_ts, lags)\n",
    "            test_lagged = test_lagged[test_lagged.index >= test.index[0]]\n",
    "            X_train = train_lagged.drop(columns='returns')\n",
    "            y_train = train_lagged['returns']\n",
    "            X_test = test_lagged.drop(columns='returns')\n",
    "            y_test = test_lagged['returns']\n",
    "            model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "            model_xgb.fit(X_train, y_train)\n",
    "            forecast_xgb = model_xgb.predict(X_test)\n",
    "            forecast_xgb = pd.Series(forecast_xgb, index=y_test.index)\n",
    "            rmse_xgb = np.sqrt(mean_squared_error(y_test, forecast_xgb)) if np.isfinite(y_test).all() and np.isfinite(forecast_xgb).all() else np.nan\n",
    "            forecast_xgb, errors_xgb = evaluate_forecast(test.reindex(y_test.index), forecast_xgb, \"XGBoost\", train, rmse_xgb)\n",
    "            forecasts['XGBoost'] = forecast_xgb\n",
    "            valid_errors_dict['XGBoost'] = errors_xgb\n",
    "        except Exception as e:\n",
    "            print(f\"Error in XGBoost fitting: {e}\")\n",
    "\n",
    "    # LSTM\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        try:\n",
    "            lags = 5\n",
    "            scaler = MinMaxScaler()\n",
    "            train_scaled = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "            test_scaled = scaler.transform(test.values.reshape(-1, 1))\n",
    "            def create_sequences(data, seq_length):\n",
    "                X, y = [], []\n",
    "                for i in range(len(data) - seq_length):\n",
    "                    X.append(data[i:i+seq_length])\n",
    "                    y.append(data[i+seq_length])\n",
    "                return np.array(X), np.array(y)\n",
    "            X_train, y_train = create_sequences(train_scaled, lags)\n",
    "            X_test, y_test = create_sequences(test_scaled, lags)\n",
    "            model_lstm = Sequential([\n",
    "                LSTM(50, activation='relu', input_shape=(lags, 1), return_sequences=False),\n",
    "                Dense(1)\n",
    "            ])\n",
    "            model_lstm.compile(optimizer='adam', loss='mse')\n",
    "            model_lstm.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
    "            forecast_lstm = []\n",
    "            current_sequence = test_scaled[-lags:].reshape(1, lags, 1)\n",
    "            for _ in range(len(test)):\n",
    "                pred = model_lstm.predict(current_sequence, verbose=0)\n",
    "                forecast_lstm.append(pred[0, 0])\n",
    "                current_sequence = np.roll(current_sequence, -1, axis=1)\n",
    "                current_sequence[0, -1, 0] = pred[0, 0]\n",
    "            forecast_lstm = scaler.inverse_transform(np.array(forecast_lstm).reshape(-1, 1)).flatten()\n",
    "            forecast_lstm = pd.Series(forecast_lstm, index=test.index)\n",
    "            rmse_lstm = np.sqrt(mean_squared_error(test, forecast_lstm)) if np.isfinite(test).all() and np.isfinite(forecast_lstm).all() else np.nan\n",
    "            forecast_lstm, errors_lstm = evaluate_forecast(test, forecast_lstm, \"LSTM\", train, rmse_lstm)\n",
    "            forecasts['LSTM'] = forecast_lstm\n",
    "            valid_errors_dict['LSTM'] = errors_lstm\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LSTM fitting: {e}\")\n",
    "\n",
    "    # Ensemble\n",
    "    try:\n",
    "        valid_forecasts = {k: v for k, v in forecasts.items() if not np.any(np.isnan(v))}\n",
    "        if valid_forecasts:\n",
    "            ensemble_forecast = pd.DataFrame(valid_forecasts).mean(axis=1)\n",
    "            rmse_ensemble = np.sqrt(mean_squared_error(test.reindex(ensemble_forecast.index), ensemble_forecast)) if np.isfinite(test).all() and np.isfinite(ensemble_forecast).all() else np.nan\n",
    "            ensemble_forecast, errors_ensemble = evaluate_forecast(test.reindex(ensemble_forecast.index), ensemble_forecast, \"Ensemble\", train, rmse_ensemble)\n",
    "            forecasts['Ensemble'] = ensemble_forecast\n",
    "            valid_errors_dict['Ensemble'] = errors_ensemble\n",
    "        else:\n",
    "            print(\"No valid forecasts for Ensemble.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Ensemble fitting: {e}\")\n",
    "\n",
    "    # RMSE Comparison\n",
    "    print(\"\\nRMSE Comparison:\")\n",
    "    for model_name, forecast in forecasts.items():\n",
    "        if not np.any(np.isnan(forecast)) and np.isfinite(test).all() and np.isfinite(forecast).all():\n",
    "            rmse = np.sqrt(mean_squared_error(test.reindex(forecast.index), forecast))\n",
    "            print(f\"{model_name}: {rmse:.4f}\")\n",
    "        else:\n",
    "            print(f\"{model_name}: Skipped due to NaN or Inf in forecast\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in forecasting section: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839f2249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
