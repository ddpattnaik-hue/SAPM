{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the CSV file\n",
    "ticker = 'APPLE INC'\n",
    "path = r\"C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\AAPL.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Data columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values\n",
    "print(data.isna().sum(), \"missing values in Adjusted column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cec1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the index is a DateTime index (assuming the CSV has a 'Date' column)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afeabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the data\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1746717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dates\n",
    "data = data.loc['2023-01-01':'2023-05-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdfa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data['Adjusted'], label='Adj Close Price')\n",
    "plt.title(f'{ticker} Line Chart')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=90, ha='left')\n",
    "plt.ylabel('Adj Close Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ced8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Resample data to monthly close prices\n",
    "monthly_data = data['Adjusted'].resample('M').last()\n",
    "\n",
    "# Plot Monthly Bar Chart\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(monthly_data.index, monthly_data.values)\n",
    "plt.title(f'{ticker} Monthly Bar Chart')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Price')\n",
    "\n",
    "# Format the x-axis labels to show only year and month\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Prepare data for candlestick chart\n",
    "# data_ohlc = data['Adjusted'].resample('2D').ohlc()\n",
    "data_ohlc = data[['Open', 'High', 'Low', 'Close']].resample('1D').agg({\n",
    "    'Open': 'first',\n",
    "    'High': 'max',\n",
    "    'Low': 'min',\n",
    "    'Close': 'last'\n",
    "}).dropna()\n",
    "data_ohlc.reset_index(inplace=True)\n",
    "data_ohlc['Date'] = data_ohlc['Date'].map(mdates.date2num)\n",
    "\n",
    "# Candlestick Chart\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "candlestick_ohlc(ax, data_ohlc.values, width=1, colorup='g', colordown='r')\n",
    "ax.xaxis_date()\n",
    "ax.set_title(f'{ticker} Candlestick Chart')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1573ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candlestickpatterns with TradeSignals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Helper functions for pattern recognition\n",
    "def is_bullish(candle):\n",
    "    return candle['Close'] > candle['Open']\n",
    "\n",
    "def is_bearish(candle):\n",
    "    return candle['Close'] < candle['Open']\n",
    "\n",
    "def calculate_mid(candle):\n",
    "    return (candle['Open'] + candle['Close']) / 2\n",
    "\n",
    "def calculate_body_size(candle):\n",
    "    return abs(candle['Close'] - candle['Open'])\n",
    "\n",
    "def calculate_upper_wick(candle):\n",
    "    return candle['High'] - max(candle['Open'], candle['Close'])\n",
    "\n",
    "def calculate_lower_wick(candle):\n",
    "    return min(candle['Open'], candle['Close']) - candle['Low']\n",
    "\n",
    "def moving_average(data, window):\n",
    "    return data['Close'].rolling(window=window).mean()\n",
    "\n",
    "def determine_trend(data, period_short=5, period_long=20):\n",
    "    short_ma = moving_average(data, period_short)\n",
    "    long_ma = moving_average(data, period_long)\n",
    "    return np.where(short_ma > long_ma, 'uptrend', 'downtrend')\n",
    "\n",
    "# Pattern-specific functions\n",
    "def is_doji(candle, tolerance=0.001):\n",
    "    return calculate_body_size(candle) <= tolerance * (candle['High'] - candle['Low'])\n",
    "\n",
    "def is_hammer(candle):\n",
    "    body_size = calculate_body_size(candle)\n",
    "    lower_wick = calculate_lower_wick(candle)\n",
    "    upper_wick = calculate_upper_wick(candle)\n",
    "    return lower_wick > 2 * body_size and upper_wick < body_size\n",
    "\n",
    "def is_inverted_hammer(candle):\n",
    "    body_size = calculate_body_size(candle)\n",
    "    lower_wick = calculate_lower_wick(candle)\n",
    "    upper_wick = calculate_upper_wick(candle)\n",
    "    return upper_wick > 2 * body_size and lower_wick < body_size\n",
    "\n",
    "def is_shooting_star(candle, previous_trend='uptrend'):\n",
    "    body_size = calculate_body_size(candle)\n",
    "    upper_wick = calculate_upper_wick(candle)\n",
    "    lower_wick = calculate_lower_wick(candle)\n",
    "    return previous_trend == 'uptrend' and upper_wick > 2 * body_size and lower_wick < body_size and is_bearish(candle)\n",
    "\n",
    "def is_spinning_top(candle):\n",
    "    body_size = calculate_body_size(candle)\n",
    "    upper_wick = calculate_upper_wick(candle)\n",
    "    lower_wick = calculate_lower_wick(candle)\n",
    "    return upper_wick > 1.5 * body_size and lower_wick > 1.5 * body_size\n",
    "\n",
    "def is_marubozu(candle, tolerance=0.001):\n",
    "    range_size = candle['High'] - candle['Low']\n",
    "    return (abs(candle['Open'] - candle['Low']) <= tolerance * range_size and \n",
    "            abs(candle['Close'] - candle['High']) <= tolerance * range_size)\n",
    "\n",
    "def is_bullish_engulfing(c1, c2):\n",
    "    return is_bearish(c1) and is_bullish(c2) and c2['Close'] > c1['Open'] and c2['Open'] < c1['Close']\n",
    "\n",
    "def is_bearish_engulfing(c1, c2):\n",
    "    return is_bullish(c1) and is_bearish(c2) and c2['Close'] < c1['Open'] and c2['Open'] > c1['Close']\n",
    "\n",
    "def is_piercing_line(c1, c2):\n",
    "    if is_bearish(c1) and is_bullish(c2):\n",
    "        return c2['Open'] < c1['Low'] and c2['Close'] > calculate_mid(c1)\n",
    "    return False\n",
    "\n",
    "def is_dark_cloud_cover(c1, c2):\n",
    "    if is_bullish(c1) and is_bearish(c2):\n",
    "        return c2['Open'] > c1['High'] and c2['Close'] < calculate_mid(c1)\n",
    "    return False\n",
    "\n",
    "def is_bullish_harami(c1, c2):\n",
    "    return is_bearish(c1) and is_bullish(c2) and c2['Open'] < c1['Open'] and c2['Close'] > c1['Close']\n",
    "\n",
    "def is_bearish_harami(c1, c2):\n",
    "    return is_bullish(c1) and is_bearish(c2) and c2['Open'] > c1['Open'] and c2['Close'] < c1['Close']\n",
    "\n",
    "def is_harami_cross(c1, c2):\n",
    "    return (is_bearish(c1) or is_bullish(c1)) and is_doji(c2) and c2['Open'] < c1['Open'] and c2['Close'] > c1['Close']\n",
    "\n",
    "def is_morning_star(c1, c2, c3):\n",
    "    return is_bearish(c1) and is_doji(c2) and is_bullish(c3) and c3['Close'] > calculate_mid(c1)\n",
    "\n",
    "def is_evening_star(c1, c2, c3):\n",
    "    return is_bullish(c1) and is_doji(c2) and is_bearish(c3) and c3['Close'] < calculate_mid(c1)\n",
    "\n",
    "def is_three_white_soldiers(c1, c2, c3):\n",
    "    return is_bullish(c1) and is_bullish(c2) and is_bullish(c3) and \\\n",
    "           c2['Open'] > c1['Close'] and c3['Open'] > c2['Close']\n",
    "\n",
    "def is_three_black_crows(c1, c2, c3):\n",
    "    return is_bearish(c1) and is_bearish(c2) and is_bearish(c3) and \\\n",
    "           c2['Open'] < c1['Close'] and c3['Open'] < c2['Close']\n",
    "\n",
    "def is_three_inside_up(c1, c2, c3):\n",
    "    return is_bearish(c1) and is_bullish(c2) and c2['Open'] < c1['Open'] and c2['Close'] > c1['Close'] and \\\n",
    "           is_bullish(c3) and c3['Close'] > c2['Close']\n",
    "\n",
    "def is_three_inside_down(c1, c2, c3):\n",
    "    return is_bullish(c1) and is_bearish(c2) and c2['Open'] > c1['Open'] and c2['Close'] < c1['Close'] and \\\n",
    "           is_bearish(c3) and c3['Close'] < c2['Close']\n",
    "\n",
    "def is_three_outside_up(c1, c2, c3):\n",
    "    return is_bearish(c1) and is_bullish(c2) and c2['Close'] > c1['Open'] and c2['Open'] < c1['Close'] and \\\n",
    "           is_bullish(c3) and c3['Close'] > c2['Close']\n",
    "\n",
    "def is_three_outside_down(c1, c2, c3):\n",
    "    return is_bullish(c1) and is_bearish(c2) and c2['Close'] < c1['Open'] and c2['Open'] > c1['Close'] and \\\n",
    "           is_bearish(c3) and c3['Close'] < c2['Close']\n",
    "\n",
    "# Main function to identify candlestick patterns and generate trade signals\n",
    "def identify_candlestick_patterns_and_signals(data):\n",
    "    # Ensure data is not empty and has required columns\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close']\n",
    "    if data.empty or not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"DataFrame is empty or missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "    \n",
    "    # Check for non-numeric data\n",
    "    if not all(data[required_columns].dtypes.apply(lambda x: np.issubdtype(x, np.number))):\n",
    "        raise ValueError(\"OHLC columns must contain numeric data.\")\n",
    "    \n",
    "    # Handle missing data\n",
    "    if data[required_columns].isna().any().any():\n",
    "        print(\"Warning: Missing values detected in OHLC columns. Dropping rows with NaN.\")\n",
    "        data = data.dropna(subset=required_columns)\n",
    "\n",
    "    # Check if data is daily to avoid unnecessary resampling\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"DataFrame index must be a DateTimeIndex.\")\n",
    "    date_diffs = data.index.to_series().diff().dropna()\n",
    "    is_daily = (date_diffs == pd.Timedelta('1 days')).all()\n",
    "    if not is_daily:\n",
    "        print(\"Warning: Data is not daily. Resampling to daily frequency.\")\n",
    "        data = data[required_columns].resample('1D').agg({\n",
    "            'Open': 'first',\n",
    "            'High': 'max',\n",
    "            'Low': 'min',\n",
    "            'Close': 'last'\n",
    "        }).dropna()\n",
    "\n",
    "    # Ensure enough data for moving averages (at least 20 days for long MA)\n",
    "    if len(data) < 20:\n",
    "        raise ValueError(\"Insufficient data for trend detection (need at least 20 days).\")\n",
    "\n",
    "    data['Pattern'] = np.nan\n",
    "    data['Pattern'] = data['Pattern'].astype(object)\n",
    "    data['Trade_Signal'] = 'Hold'\n",
    "\n",
    "    # Track detected patterns for logging\n",
    "    detected_patterns = set()\n",
    "\n",
    "    for i in range(3, len(data)):  # Start at 3 to allow three-candle patterns\n",
    "        candle = data.iloc[i]\n",
    "        prev_candle_1 = data.iloc[i - 1]\n",
    "        prev_candle_2 = data.iloc[i - 2]\n",
    "        prev_candle_3 = data.iloc[i - 3]\n",
    "\n",
    "        # Determine the trend using moving averages\n",
    "        previous_trend = determine_trend(data.iloc[:i+1])[-1]\n",
    "\n",
    "        # Identify Patterns and Generate Trade Signals\n",
    "        if is_doji(candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Doji'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Hold'\n",
    "            detected_patterns.add('Doji')\n",
    "\n",
    "        elif previous_trend == 'downtrend' and is_hammer(candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Hammer'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Hammer')\n",
    "\n",
    "        elif previous_trend == 'uptrend' and is_hammer(candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Hanging Man'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Hanging Man')\n",
    "\n",
    "        elif previous_trend == 'downtrend' and is_inverted_hammer(candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Inverted Hammer'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Inverted Hammer')\n",
    "\n",
    "        elif previous_trend == 'uptrend' and is_shooting_star(candle, previous_trend):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Shooting Star'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Shooting Star')\n",
    "\n",
    "        elif is_spinning_top(candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Spinning Top'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Hold'\n",
    "            detected_patterns.add('Spinning Top')\n",
    "\n",
    "        elif is_marubozu(candle):\n",
    "            if is_bullish(candle):\n",
    "                data.loc[data.index[i], 'Pattern'] = 'Bullish Marubozu'\n",
    "                data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "                detected_patterns.add('Bullish Marubozu')\n",
    "            else:\n",
    "                data.loc[data.index[i], 'Pattern'] = 'Bearish Marubozu'\n",
    "                data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "                detected_patterns.add('Bearish Marubozu')\n",
    "\n",
    "        elif previous_trend == 'downtrend' and is_piercing_line(prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Piercing Line'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Piercing Line')\n",
    "\n",
    "        elif previous_trend == 'uptrend' and is_dark_cloud_cover(prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Dark Cloud Cover'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Dark Cloud Cover')\n",
    "\n",
    "        elif is_bullish_engulfing(prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Bullish Engulfing'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Bullish Engulfing')\n",
    "\n",
    "        elif is_bearish_engulfing(prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Bearish Engulfing'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Bearish Engulfing')\n",
    "\n",
    "        elif is_bullish_harami(prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Bullish Harami'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Bullish Harami')\n",
    "\n",
    "        elif is_bearish_harami(prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Bearish Harami'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Bearish Harami')\n",
    "\n",
    "        elif is_harami_cross(prev_candle_1, candle):\n",
    "            if is_bearish(prev_candle_1):\n",
    "                data.loc[data.index[i], 'Pattern'] = 'Bullish Harami Cross'\n",
    "                data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "                detected_patterns.add('Bullish Harami Cross')\n",
    "            else:\n",
    "                data.loc[data.index[i], 'Pattern'] = 'Bearish Harami Cross'\n",
    "                data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "                detected_patterns.add('Bearish Harami Cross')\n",
    "\n",
    "        elif is_morning_star(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Morning Star'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Morning Star')\n",
    "\n",
    "        elif is_evening_star(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Evening Star'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Evening Star')\n",
    "\n",
    "        elif is_three_white_soldiers(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Three White Soldiers'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Three White Soldiers')\n",
    "\n",
    "        elif is_three_black_crows(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Three Black Crows'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Three Black Crows')\n",
    "\n",
    "        elif is_three_inside_up(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Three Inside Up'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Three Inside Up')\n",
    "\n",
    "        elif is_three_inside_down(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Three Inside Down'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Three Inside Down')\n",
    "\n",
    "        elif is_three_outside_up(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Three Outside Up'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Buy'\n",
    "            detected_patterns.add('Three Outside Up')\n",
    "\n",
    "        elif is_three_outside_down(prev_candle_2, prev_candle_1, candle):\n",
    "            data.loc[data.index[i], 'Pattern'] = 'Three Outside Down'\n",
    "            data.loc[data.index[i], 'Trade_Signal'] = 'Sell'\n",
    "            detected_patterns.add('Three Outside Down')\n",
    "\n",
    "    # Log detected patterns\n",
    "    print(\"Detected patterns:\", sorted(detected_patterns) if detected_patterns else \"None\")\n",
    "    if not detected_patterns:\n",
    "        print(\"Warning: No patterns detected. Check data or pattern logic.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "try:\n",
    "    ticker = 'AAPL'  # Define ticker\n",
    "    # Note: Load data in a separate cell or adjust path as needed\n",
    "    # data = pd.read_csv(r'C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\AAPL.csv')\n",
    "    # data['Date'] = pd.to_datetime(data['Date'])\n",
    "    # data.set_index('Date', inplace=True)\n",
    "\n",
    "    data = identify_candlestick_patterns_and_signals(data)\n",
    "    print(\"Columns in DataFrame:\", data.columns)\n",
    "\n",
    "    # Save results to Excel\n",
    "    output_path = r'C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\APPLE_Candlestickpatterns_with_TradeSignals.xlsx'\n",
    "    data.to_excel(output_path, sheet_name='Candlestick Patterns')\n",
    "    print(\"Excel file generated successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in pattern recognition: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Candlestick Patterns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Function to plot candlestick chart for a specific pattern\n",
    "def plot_pattern(data, pattern_name, max_plots=3):\n",
    "    # Ensure required columns for plotting\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close', 'Pattern']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns for plotting: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "    # Ensure DateTime index\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"DataFrame index must be a DateTimeIndex.\")\n",
    "\n",
    "    # Filter for the specific pattern, excluding NaN\n",
    "    pattern_data = data[data['Pattern'] == pattern_name]\n",
    "    \n",
    "    if pattern_data.empty:\n",
    "        print(f\"No occurrences of {pattern_name} found.\")\n",
    "        return\n",
    "\n",
    "    # Limit the number of plots to avoid overwhelming output\n",
    "    plot_count = 0\n",
    "    for i in pattern_data.index:\n",
    "        if plot_count >= max_plots:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Extract a small window of data around the pattern using Timedelta\n",
    "            start_idx = i - pd.Timedelta(days=5)\n",
    "            end_idx = i + pd.Timedelta(days=5)\n",
    "            window = data.loc[start_idx:end_idx]\n",
    "\n",
    "            if window.empty:\n",
    "                print(f\"Skipping plot for {pattern_name} on {i.date()}: Empty window.\")\n",
    "                continue\n",
    "\n",
    "            data_ohlc = window[['Open', 'High', 'Low', 'Close']].copy()\n",
    "            data_ohlc.reset_index(inplace=True)\n",
    "            data_ohlc['Date'] = data_ohlc['Date'].map(mdates.date2num)\n",
    "\n",
    "            # Plot the candlestick chart\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            candlestick_ohlc(ax, data_ohlc.values, width=0.6, colorup='g', colordown='r')\n",
    "            ax.xaxis_date()\n",
    "            ax.set_title(f'{pattern_name} Pattern on {i.date()}')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel('Price')\n",
    "\n",
    "            # Rotate x-axis labels by 45 degrees for better readability\n",
    "            ax.xaxis.set_tick_params(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plot_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting {pattern_name} on {i.date()}: {e}\")\n",
    "\n",
    "# Plot patterns one by one\n",
    "try:\n",
    "    patterns_to_plot = data['Pattern'].dropna().unique()  # Exclude NaN\n",
    "    for pattern in patterns_to_plot:\n",
    "        plot_pattern(data, pattern, max_plots=3)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectiveness of the Trade Signals\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the effectiveness of the trade signals\n",
    "def calculate_strategy_performance(df):\n",
    "    # Ensure required columns\n",
    "    required_columns = ['Trade_Signal']\n",
    "    price_column = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
    "    required_columns.append(price_column)\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {df.columns}\")\n",
    "\n",
    "    # Ensure DateTime index\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"DataFrame index must be a DateTimeIndex.\")\n",
    "\n",
    "    # Initialize columns\n",
    "    df['Position'] = 0  # 1 for holding, 0 for not holding\n",
    "    df['Strategy_Returns'] = 0.0  # Daily returns of the strategy\n",
    "    df['Market_Returns'] = df[price_column].pct_change()  # Daily returns of buy-and-hold\n",
    "\n",
    "    # Handle missing returns\n",
    "    df['Market_Returns'] = df['Market_Returns'].fillna(0)\n",
    "\n",
    "    # Initialize variables\n",
    "    position = 0\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[df.index[i], 'Trade_Signal'] == 'Buy':\n",
    "            position = 1\n",
    "        elif df.loc[df.index[i], 'Trade_Signal'] == 'Sell':\n",
    "            position = 0\n",
    "        # 'Hold' maintains the current position\n",
    "        df.loc[df.index[i], 'Position'] = position\n",
    "        df.loc[df.index[i], 'Strategy_Returns'] = position * df.loc[df.index[i], 'Market_Returns']\n",
    "\n",
    "    # Calculate cumulative returns\n",
    "    df['Cumulative_Strategy_Returns'] = (1 + df['Strategy_Returns']).cumprod() - 1\n",
    "    df['Cumulative_Market_Returns'] = (1 + df['Market_Returns']).cumprod() - 1\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    annual_trading_days = 252\n",
    "    strategy_annualized_return = df['Strategy_Returns'].mean() * annual_trading_days\n",
    "    strategy_volatility = df['Strategy_Returns'].std() * np.sqrt(annual_trading_days)\n",
    "    sharpe_ratio_strategy = strategy_annualized_return / strategy_volatility if strategy_volatility != 0 else np.nan\n",
    "    market_annualized_return = df['Market_Returns'].mean() * annual_trading_days\n",
    "    market_volatility = df['Market_Returns'].std() * np.sqrt(annual_trading_days)\n",
    "    sharpe_ratio_market = market_annualized_return / market_volatility if market_volatility != 0 else np.nan\n",
    "    max_drawdown_strategy = (df['Cumulative_Strategy_Returns'].cummax() - df['Cumulative_Strategy_Returns']).max()\n",
    "    max_drawdown_market = (df['Cumulative_Market_Returns'].cummax() - df['Cumulative_Market_Returns']).max()\n",
    "\n",
    "    # Print performance metrics\n",
    "    print(f\"Strategy Performance Metrics:\")\n",
    "    print(f\"  Annualized Return: {strategy_annualized_return:.4f}\")\n",
    "    print(f\"  Volatility: {strategy_volatility:.4f}\")\n",
    "    print(f\"  Sharpe Ratio: {sharpe_ratio_strategy:.4f}\")\n",
    "    print(f\"  Max Drawdown: {max_drawdown_strategy:.4f}\")\n",
    "    print(f\"Market (Buy-and-Hold) Performance Metrics:\")\n",
    "    print(f\"  Annualized Return: {market_annualized_return:.4f}\")\n",
    "    print(f\"  Volatility: {market_volatility:.4f}\")\n",
    "    print(f\"  Sharpe Ratio: {sharpe_ratio_market:.4f}\")\n",
    "    print(f\"  Max Drawdown: {max_drawdown_market:.4f}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "try:\n",
    "    ticker = 'AAPL'  # Define ticker\n",
    "    data = calculate_strategy_performance(data)\n",
    "    print(\"Columns in DataFrame:\", data.columns)\n",
    "\n",
    "    # Save results to Excel\n",
    "    output_path = r'C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\APPLE_Candlestickpatterns_Strategy.xlsx'\n",
    "    data.to_excel(output_path, sheet_name='Strategy Performance')\n",
    "    print(\"Excel file generated successfully!\")\n",
    "\n",
    "    # Plot cumulative returns\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data.index, data['Cumulative_Strategy_Returns'], label='Strategy Returns')\n",
    "    plt.plot(data.index, data['Cumulative_Market_Returns'], label='Market Returns (Buy and Hold)')\n",
    "    plt.title(f'{ticker} Strategy Performance vs. Market')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Returns')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in performance evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicators and Oscillators\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the CSV file\n",
    "ticker = 'APPLE INC'\n",
    "path = r\"C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\AAPL.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    # Validate required columns\n",
    "    required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Adjusted']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "    # Ensure the index is a DateTime index\n",
    "    data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "    if data['Date'].isna().any():\n",
    "        raise ValueError(\"Invalid date format in 'Date' column.\")\n",
    "    data.set_index('Date', inplace=True)\n",
    "\n",
    "    # Verify numeric data\n",
    "    if not all(data[['Open', 'High', 'Low', 'Close', 'Adjusted']].dtypes.apply(lambda x: np.issubdtype(x, np.number))):\n",
    "        raise ValueError(\"OHLC and Adjusted columns must contain numeric data.\")\n",
    "\n",
    "    # Display the first few rows of the data\n",
    "    print(data.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in data loading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Moving Average (SMA)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 200:\n",
    "        raise ValueError(\"Insufficient data for 200-day SMA (need at least 200 days).\")\n",
    "\n",
    "    # Simple Moving Average (SMA)\n",
    "    data['SMA_50'] = data['Adjusted'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Adjusted'].rolling(window=200).mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data['Adjusted'], label='Adj Close Price')\n",
    "    plt.plot(data['SMA_50'], label='50-day SMA')\n",
    "    plt.plot(data['SMA_200'], label='200-day SMA')\n",
    "    plt.title(f'{ticker} Moving Averages')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in SMA calculation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512baa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA 20 and 50 days\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "try:\n",
    "    # Validate required columns\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close', 'Adjusted']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 50:\n",
    "        raise ValueError(\"Insufficient data for 50-day EMA (need at least 50 days).\")\n",
    "\n",
    "    # Calculate the 20-day and 50-day EMA\n",
    "    data['EMA_20'] = data['Adjusted'].ewm(span=20, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Adjusted'].ewm(span=50, adjust=False).mean()\n",
    "\n",
    "    # Prepare data for candlestick chart\n",
    "    data_ohlc = data[['Open', 'High', 'Low', 'Close']].copy()\n",
    "    data_ohlc.reset_index(inplace=True)\n",
    "    data_ohlc['Date'] = data_ohlc['Date'].map(mdates.date2num)\n",
    "\n",
    "    # Candlestick Chart with 20-day and 50-day EMA\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    candlestick_ohlc(ax, data_ohlc.values, width=0.6, colorup='g', colordown='r')\n",
    "\n",
    "    # Plot the 20-day and 50-day EMA\n",
    "    ax.plot(mdates.date2num(data.index), data['EMA_20'], label='20-day EMA', color='blue', linewidth=1.5)\n",
    "    ax.plot(mdates.date2num(data.index), data['EMA_50'], label='50-day EMA', color='red', linewidth=1.5)\n",
    "\n",
    "    # Format the plot\n",
    "    ax.xaxis_date()\n",
    "    ax.set_title(f'{ticker} Candlestick Chart with 20-day and 50-day EMA')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in EMA candlestick plot: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA on Line Chart\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 50:\n",
    "        raise ValueError(\"Insufficient data for 50-day EMA (need at least 50 days).\")\n",
    "\n",
    "    # Calculate the 20-day and 50-day EMA\n",
    "    data['EMA_20'] = data['Adjusted'].ewm(span=20, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Adjusted'].ewm(span=50, adjust=False).mean()\n",
    "\n",
    "    # Plot the Adjusted Close with 20-day and 50-day EMA\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data['Adjusted'], label='Adjusted Close', color='black', linewidth=2)\n",
    "    plt.plot(data['EMA_20'], label='20-day EMA', color='blue', linewidth=1.5)\n",
    "    plt.plot(data['EMA_50'], label='50-day EMA', color='red', linewidth=1.5)\n",
    "\n",
    "    # Formatting the plot\n",
    "    plt.title(f'{ticker} Adjusted Close with 20-day and 50-day EMA')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in EMA line chart: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple EMAs on Line Chart\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 200:\n",
    "        raise ValueError(\"Insufficient data for 200-day EMA (need at least 200 days).\")\n",
    "\n",
    "    # Calculate multiple EMAs\n",
    "    ema_periods = [20, 50, 100, 200]\n",
    "    for period in ema_periods:\n",
    "        data[f'EMA_{period}'] = data['Adjusted'].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "    # Plot the Adjusted Close with all EMAs\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(data['Adjusted'], label='Adjusted Close', color='black', linewidth=2)\n",
    "\n",
    "    # Plot each EMA\n",
    "    colors = ['blue', 'red', 'green', 'purple']\n",
    "    for i, period in enumerate(ema_periods):\n",
    "        plt.plot(data[f'EMA_{period}'], label=f'{period}-day EMA', color=colors[i], linewidth=1.5)\n",
    "\n",
    "    # Formatting the plot\n",
    "    plt.title(f'{ticker} Adjusted Close with EMAs')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in multiple EMAs plot: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Strength Index\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 14:\n",
    "        raise ValueError(\"Insufficient data for 14-day RSI (need at least 14 days).\")\n",
    "\n",
    "    # Function to calculate the Relative Strength Index (RSI)\n",
    "    def calculate_rsi(data, window):\n",
    "        delta = data['Adjusted'].diff(1)\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    # Calculate RSI\n",
    "    data['RSI'] = calculate_rsi(data, 14)\n",
    "\n",
    "    # Calculate dynamic overbought and oversold thresholds\n",
    "    mean_rsi = data['RSI'].mean()\n",
    "    std_rsi = data['RSI'].std()\n",
    "    overbought_dynamic = mean_rsi + std_rsi\n",
    "    oversold_dynamic = mean_rsi - std_rsi\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data['RSI'], label='RSI', color='blue')\n",
    "    plt.axhline(70, linestyle='--', alpha=0.5, color='red', label='Overbought (70)')\n",
    "    plt.axhline(30, linestyle='--', alpha=0.5, color='green', label='Oversold (30)')\n",
    "    plt.axhline(overbought_dynamic, linestyle=':', alpha=0.3, color='red', label=f'Dynamic Overbought ({overbought_dynamic:.2f})')\n",
    "    plt.axhline(oversold_dynamic, linestyle=':', alpha=0.3, color='green', label=f'Dynamic Oversold ({oversold_dynamic:.2f})')\n",
    "    plt.title(f'{ticker} Relative Strength Index (RSI)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('RSI')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in RSI calculation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4137f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 26:\n",
    "        raise ValueError(\"Insufficient data for MACD (need at least 26 days).\")\n",
    "\n",
    "    # MACD\n",
    "    exp1 = data['Adjusted'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = data['Adjusted'].ewm(span=26, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data.index, macd, label='MACD', color='green')\n",
    "    plt.plot(data.index, signal, label='Signal Line', color='red')\n",
    "    plt.axhline(0, linestyle='--', alpha=0.5, color='black', label='Zero Line')\n",
    "    plt.title(f'{ticker} MACD')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('MACD')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in MACD calculation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MACD Histogram\n",
    "macd_histogram = macd - signal\n",
    "\n",
    "# Plotting the MACD line, Signal line, and MACD Histogram\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot the MACD Histogram\n",
    "plt.bar(data.index, macd_histogram, label='MACD Histogram', color='blue', alpha=0.5)\n",
    "\n",
    "plt.title(f'{ticker} MACD Histogram')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('MACD')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eda0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Bands\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 20:\n",
    "        raise ValueError(\"Insufficient data for Bollinger Bands (need at least 20 days).\")\n",
    "\n",
    "    # Bollinger Bands\n",
    "    data['Middle Band'] = data['Adjusted'].rolling(window=20).mean()\n",
    "    data['Upper Band'] = data['Middle Band'] + 2 * data['Adjusted'].rolling(window=20).std()\n",
    "    data['Lower Band'] = data['Middle Band'] - 2 * data['Adjusted'].rolling(window=20).std()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data['Adjusted'], label='Adj Close Price')\n",
    "    plt.plot(data['Middle Band'], label='Middle Band')\n",
    "    plt.plot(data['Upper Band'], label='Upper Band')\n",
    "    plt.plot(data['Lower Band'], label='Lower Band')\n",
    "    plt.fill_between(data.index, data['Upper Band'], data['Lower Band'], alpha=0.1)\n",
    "    plt.title(f'{ticker} Bollinger Bands')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Bollinger Bands calculation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18272a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Oscillator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Validate required columns\n",
    "    required_columns = ['High', 'Low', 'Adjusted']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 14:\n",
    "        raise ValueError(\"Insufficient data for Stochastic Oscillator (need at least 14 days).\")\n",
    "\n",
    "    # Function to calculate the Stochastic Oscillator\n",
    "    def stochastic_oscillator(data, window):\n",
    "        low_min = data['Low'].rolling(window=window).min()\n",
    "        high_max = data['High'].rolling(window=window).max()\n",
    "        stoch = 100 * ((data['Adjusted'] - low_min) / (high_max - low_min))\n",
    "        return stoch\n",
    "\n",
    "    # Calculate %K and %D\n",
    "    data['%K'] = stochastic_oscillator(data, 14)\n",
    "    data['%D'] = data['%K'].rolling(window=3).mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data.index, data['%K'], label='Stochastic %K (14)', color='blue')\n",
    "    plt.plot(data.index, data['%D'], label='Stochastic %D (3)', color='red')\n",
    "    plt.axhline(80, linestyle='--', alpha=0.5, color='red', label='Overbought (80)')\n",
    "    plt.axhline(20, linestyle='--', alpha=0.5, color='green', label='Oversold (20)')\n",
    "    plt.title(f'{ticker} Stochastic Oscillator')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Stochastic')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Stochastic Oscillator calculation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09334073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Oscillator Indication Using Dynamic Overbought and Oversold Thresholds\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Validate required columns\n",
    "    required_columns = ['High', 'Low', 'Adjusted']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 14:\n",
    "        raise ValueError(\"Insufficient data for Stochastic Oscillator (need at least 14 days).\")\n",
    "\n",
    "    # Function to calculate the Stochastic Oscillator\n",
    "    def stochastic_oscillator(data, window):\n",
    "        low_min = data['Low'].rolling(window=window).min()\n",
    "        high_max = data['High'].rolling(window=window).max()\n",
    "        stoch = 100 * ((data['Adjusted'] - low_min) / (high_max - low_min))\n",
    "        return stoch\n",
    "\n",
    "    # Calculate %K and %D\n",
    "    data['%K'] = stochastic_oscillator(data, 14)\n",
    "    data['%D'] = data['%K'].rolling(window=3).mean()\n",
    "\n",
    "    # Calculate dynamic overbought and oversold thresholds\n",
    "    mean_k = data['%K'].mean()\n",
    "    std_k = data['%K'].std()\n",
    "    overbought = mean_k + std_k\n",
    "    oversold = mean_k - std_k\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data.index, data['%K'], label='Stochastic %K (14)', color='blue')\n",
    "    plt.plot(data.index, data['%D'], label='Stochastic %D (3)', color='red')\n",
    "    plt.axhline(80, linestyle='--', alpha=0.5, color='red', label='Overbought (80)')\n",
    "    plt.axhline(20, linestyle='--', alpha=0.5, color='green', label='Oversold (20)')\n",
    "    plt.axhline(overbought, linestyle=':', alpha=0.3, color='red', label=f'Dynamic Overbought ({overbought:.2f})')\n",
    "    plt.axhline(oversold, linestyle=':', alpha=0.3, color='green', label=f'Dynamic Oversold ({oversold:.2f})')\n",
    "    plt.title(f'{ticker} Stochastic Oscillator with Dynamic Thresholds')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Stochastic')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Stochastic Oscillator with dynamic thresholds: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectified Head and Shoulder Patterns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 50:\n",
    "        raise ValueError(\"Insufficient data for Head and Shoulders (need at least 50 days).\")\n",
    "\n",
    "    # Define a function to identify Head and Shoulders pattern\n",
    "    def identify_head_and_shoulders(data, window=14):\n",
    "        peaks, _ = find_peaks(data['Adjusted'], distance=window)\n",
    "        troughs, _ = find_peaks(-data['Adjusted'], distance=window)\n",
    "        \n",
    "        patterns = []\n",
    "        for i in range(1, len(peaks) - 1):\n",
    "            left_peak = peaks[i - 1]\n",
    "            head_peak = peaks[i]\n",
    "            right_peak = peaks[i + 1]\n",
    "            \n",
    "            left_trough_idx = np.where((troughs < head_peak) & (troughs > left_peak))[0]\n",
    "            right_trough_idx = np.where((troughs > head_peak) & (troughs < right_peak))[0]\n",
    "\n",
    "            if left_trough_idx.size > 0 and right_trough_idx.size > 0:\n",
    "                left_trough = troughs[left_trough_idx[-1]]\n",
    "                right_trough = troughs[right_trough_idx[0]]\n",
    "\n",
    "                # Conditions to validate the Head and Shoulders pattern\n",
    "                if (data['Adjusted'].iloc[head_peak] > data['Adjusted'].iloc[left_peak]) and \\\n",
    "                   (data['Adjusted'].iloc[head_peak] > data['Adjusted'].iloc[right_peak]) and \\\n",
    "                   (data['Adjusted'].iloc[head_peak] - data['Adjusted'].iloc[left_trough] > \n",
    "                    data['Adjusted'].iloc[left_peak] - data['Adjusted'].iloc[left_trough]) and \\\n",
    "                   (data['Adjusted'].iloc[head_peak] - data['Adjusted'].iloc[right_trough] > \n",
    "                    data['Adjusted'].iloc[right_peak] - data['Adjusted'].iloc[right_trough]):\n",
    "                    \n",
    "                    patterns.append((left_peak, head_peak, right_peak))\n",
    "\n",
    "        return patterns, peaks, troughs\n",
    "\n",
    "    # Identify Head and Shoulders patterns\n",
    "    patterns, peaks, troughs = identify_head_and_shoulders(data)\n",
    "\n",
    "    # Convert peaks and troughs to DataFrame for plotting\n",
    "    peaks_df = pd.DataFrame(data['Adjusted'].iloc[peaks])\n",
    "    troughs_df = pd.DataFrame(data['Adjusted'].iloc[troughs])\n",
    "\n",
    "    # Plotting the identified patterns\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.plot(data.index, data['Adjusted'], label='Adj Close Price')\n",
    "\n",
    "    # Plot peaks and troughs\n",
    "    ax.scatter(peaks_df.index, peaks_df['Adjusted'], marker='^', color='red', label='Peaks')\n",
    "    ax.scatter(troughs_df.index, troughs_df['Adjusted'], marker='v', color='blue', label='Troughs')\n",
    "\n",
    "    # Highlight identified Head and Shoulders patterns\n",
    "    for i, (left_peak, head_peak, right_peak) in enumerate(patterns):\n",
    "        label = 'Head & Shoulders' if i == 0 else None  # Avoid duplicate legend entries\n",
    "        ax.plot(data.index[[left_peak, head_peak, right_peak]], \n",
    "                data['Adjusted'].iloc[[left_peak, head_peak, right_peak]], \n",
    "                color='green', linewidth=1, label=label)\n",
    "\n",
    "    ax.set_title(f'{ticker} Head and Shoulders Patterns')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Detected {len(patterns)} Head and Shoulders patterns.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Head and Shoulders detection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend Line\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data['Adjusted'], label='Adj Close Price')\n",
    "plt.plot(data.index, data['Adjusted'].rolling(window=50).mean(), label='Trend Line', linestyle='--')\n",
    "plt.title(f'{ticker} Trend Line')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support and Resistance Levels \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 30:\n",
    "        raise ValueError(\"Insufficient data for support/resistance levels (need at least 30 days).\")\n",
    "\n",
    "    # Identify local minima and maxima\n",
    "    n = 30  # Number of points to be checked before and after\n",
    "    data['Min'] = data.iloc[argrelextrema(data['Adjusted'].values, np.less_equal, order=n)[0]]['Adjusted']\n",
    "    data['Max'] = data.iloc[argrelextrema(data['Adjusted'].values, np.greater_equal, order=n)[0]]['Adjusted']\n",
    "\n",
    "    # Filter out NaN values\n",
    "    support_levels = data.dropna(subset=['Min'])\n",
    "    resistance_levels = data.dropna(subset=['Max'])\n",
    "\n",
    "    # Plotting the close price along with support and resistance levels\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(data['Adjusted'], label='Adj Close Price')\n",
    "    plt.scatter(support_levels.index, support_levels['Min'], label='Support Level', color='green', marker='^')\n",
    "    plt.scatter(resistance_levels.index, resistance_levels['Max'], label='Resistance Level', color='red', marker='v')\n",
    "    plt.title(f'{ticker} Support and Resistance Levels')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Detected {len(support_levels)} support levels and {len(resistance_levels)} resistance levels.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in support/resistance calculation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume Analysis\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(data.index, data['Volume'], label='Volume', color='gray')\n",
    "plt.title(f'{ticker} Volume Analysis')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibonacci Retracement Levels\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Validate required column\n",
    "    if 'Adjusted' not in data.columns:\n",
    "        raise ValueError(\"Missing 'Adjusted' column.\")\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(data) < 2:\n",
    "        raise ValueError(\"Insufficient data for Fibonacci retracement (need at least 2 days).\")\n",
    "\n",
    "    # Function to plot Fibonacci retracement levels\n",
    "    def plot_fibonacci_retracement(data, lookback_days=None):\n",
    "        if lookback_days:\n",
    "            data = data.tail(lookback_days)\n",
    "        max_price = data['Adjusted'].max()\n",
    "        min_price = data['Adjusted'].min()\n",
    "        difference = max_price - min_price\n",
    "        first_level = max_price - difference * 0.236\n",
    "        second_level = max_price - difference * 0.382\n",
    "        third_level = max_price - difference * 0.618\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(data['Adjusted'], label='Adj Close Price')\n",
    "        plt.axhline(max_price, linestyle='--', alpha=0.5, color='red', label='0%')\n",
    "        plt.axhline(first_level, linestyle='--', alpha=0.5, color='orange', label='23.6%')\n",
    "        plt.axhline(second_level, linestyle='--', alpha=0.5, color='yellow', label='38.2%')\n",
    "        plt.axhline(third_level, linestyle='--', alpha=0.5, color='green', label='61.8%')\n",
    "        plt.axhline(min_price, linestyle='--', alpha=0.5, color='blue', label='100%')\n",
    "        plt.title(f'{ticker} Fibonacci Retracement Levels')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_fibonacci_retracement(data, lookback_days=252)  # Last year of data\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Fibonacci retracement: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicators and Oscillators Based Trading Strategy\n",
    "\n",
    "# Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the CSV file\n",
    "ticker = 'APPLE INC'\n",
    "path = r\"C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\AAPL.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    # Validate required columns\n",
    "    required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Adjusted']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "    # Ensure the index is a DateTime index\n",
    "    data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "    if data['Date'].isna().any():\n",
    "        raise ValueError(\"Invalid date format in 'Date' column.\")\n",
    "    data.set_index('Date', inplace=True)\n",
    "\n",
    "    # Verify numeric data\n",
    "    if not all(data[['Open', 'High', 'Low', 'Close', 'Adjusted']].dtypes.apply(lambda x: np.issubdtype(x, np.number))):\n",
    "        raise ValueError(\"OHLC and Adjusted columns must contain numeric data.\")\n",
    "\n",
    "    # Display the first few rows and data frequency\n",
    "    print(\"Data head:\")\n",
    "    print(data.head())\n",
    "    print(\"Data frequency check:\")\n",
    "    print(data.index.to_series().diff().value_counts())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in data loading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dates\n",
    "data = data.loc['2023-01-01':'2023-06-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade Signals with Candle Stick Patterns or Execute the Next Cell in Case Candle Stick Based Trading is Not Intended\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_indicator_signals(data):\n",
    "    try:\n",
    "        # Validate required columns\n",
    "        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "        # Ensure DateTime index\n",
    "        if not isinstance(data.index, pd.DatetimeIndex):\n",
    "            data.index = pd.to_datetime(data.index)\n",
    "            \n",
    "        # Use Adjusted if available, else Close\n",
    "        if 'Adjusted' not in data.columns:\n",
    "            data['Adjusted'] = data['Close']\n",
    "            \n",
    "        # Check for sufficient data\n",
    "        if len(data) < 50:\n",
    "            raise ValueError(\"Insufficient data for indicators (need at least 50 days).\")\n",
    "\n",
    "        # Indicator Calculations\n",
    "        data['SMA_20'] = data['Adjusted'].rolling(window=20, min_periods=20).mean()\n",
    "        data['SMA_50'] = data['Adjusted'].rolling(window=50, min_periods=50).mean()\n",
    "        data['EMA_20'] = data['Adjusted'].ewm(span=20, adjust=False).mean()\n",
    "        data['Volume_MA'] = data['Volume'].rolling(window=20, min_periods=20).mean()\n",
    "\n",
    "        def calculate_atr(data, window):\n",
    "            hl = data['High'] - data['Low']\n",
    "            hc = abs(data['High'] - data['Close'].shift(1))\n",
    "            lc = abs(data['Low'] - data['Close'].shift(1))\n",
    "            tr = pd.concat([hl, hc, lc], axis=1).max(axis=1)\n",
    "            return tr.rolling(window, min_periods=1).mean()\n",
    "        data['ATR'] = calculate_atr(data, 14)\n",
    "\n",
    "        def calculate_rsi(data, window):\n",
    "            delta = data['Adjusted'].diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            avg_gain = gain.rolling(window, min_periods=window).mean()\n",
    "            avg_loss = loss.rolling(window, min_periods=window).mean()\n",
    "            rs = avg_gain / avg_loss\n",
    "            rs = rs.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            return 100 - (100 / (1 + rs))\n",
    "        data['RSI'] = calculate_rsi(data, 14)\n",
    "\n",
    "        exp1 = data['Adjusted'].ewm(span=12, adjust=False).mean()\n",
    "        exp2 = data['Adjusted'].ewm(span=26, adjust=False).mean()\n",
    "        data['MACD'] = exp1 - exp2\n",
    "        data['MACD_Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "        data['MACD_Hist'] = data['MACD'] - data['MACD_Signal']\n",
    "\n",
    "        data['Middle Band'] = data['Adjusted'].rolling(window=20).mean()\n",
    "        std = data['Adjusted'].rolling(window=20).std()\n",
    "        data['Upper Band'] = data['Middle Band'] + 1.5 * std\n",
    "        data['Lower Band'] = data['Middle Band'] - 1.5 * std\n",
    "\n",
    "        def stochastic_oscillator(data, window):\n",
    "            low_min = data['Low'].rolling(window=window).min()\n",
    "            high_max = data['High'].rolling(window=window).max()\n",
    "            stoch = 100 * ((data['Adjusted'] - low_min) / (high_max - low_min))\n",
    "            return stoch\n",
    "        data['%K'] = stochastic_oscillator(data, 14)\n",
    "        data['%D'] = data['%K'].rolling(window=3).mean()\n",
    "\n",
    "        n = 20\n",
    "        data['Rolling_Low'] = data['Low'].rolling(n, min_periods=n).min()\n",
    "        data['Rolling_High'] = data['High'].rolling(n, min_periods=n).max()\n",
    "        data['Support'] = data['Rolling_Low'] + 0.2 * data['ATR']\n",
    "        data['Resistance'] = data['Rolling_High'] - 0.2 * data['ATR']\n",
    "\n",
    "        # Fibonacci Retracement (3-month rolling)\n",
    "        data['Fib_23.6'] = np.nan\n",
    "        data['Fib_38.2'] = np.nan\n",
    "        data['Fib_61.8'] = np.nan\n",
    "        for i in range(63, len(data)):\n",
    "            window = data.iloc[i-63:i]\n",
    "            max_price = window['Adjusted'].max()\n",
    "            min_price = window['Adjusted'].min()\n",
    "            difference = max_price - min_price\n",
    "            data.loc[data.index[i], 'Fib_23.6'] = max_price - difference * 0.236\n",
    "            data.loc[data.index[i], 'Fib_38.2'] = max_price - difference * 0.382\n",
    "            data.loc[data.index[i], 'Fib_61.8'] = max_price - difference * 0.618\n",
    "\n",
    "        # Candlestick Patterns\n",
    "        data['Candlestick_Pattern'] = np.nan\n",
    "        for i in range(3, len(data)):\n",
    "            # Bullish Engulfing\n",
    "            if (data['Close'].iloc[i-1] < data['Open'].iloc[i-1] and\n",
    "                data['Close'].iloc[i] > data['Open'].iloc[i] and\n",
    "                data['Close'].iloc[i] > data['Open'].iloc[i-1] and\n",
    "                data['Open'].iloc[i] < data['Close'].iloc[i-1] and\n",
    "                data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Bullish_Engulfing'\n",
    "            # Bearish Engulfing\n",
    "            elif (data['Close'].iloc[i-1] > data['Open'].iloc[i-1] and\n",
    "                  data['Close'].iloc[i] < data['Open'].iloc[i] and\n",
    "                  data['Close'].iloc[i] < data['Open'].iloc[i-1] and\n",
    "                  data['Open'].iloc[i] > data['Close'].iloc[i-1] and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Bearish_Engulfing'\n",
    "            # Morning Star\n",
    "            elif (data['Close'].iloc[i-2] < data['Open'].iloc[i-2] and\n",
    "                  abs(data['Close'].iloc[i-1] - data['Open'].iloc[i-1]) < data['ATR'].iloc[i-1] * 0.2 and\n",
    "                  data['Close'].iloc[i] > data['Open'].iloc[i] and\n",
    "                  data['Close'].iloc[i] > data['Middle Band'].iloc[i] and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Morning_Star'\n",
    "            # Evening Star\n",
    "            elif (data['Close'].iloc[i-2] > data['Open'].iloc[i-2] and\n",
    "                  abs(data['Close'].iloc[i-1] - data['Open'].iloc[i-1]) < data['ATR'].iloc[i-1] * 0.2 and\n",
    "                  data['Close'].iloc[i] < data['Open'].iloc[i] and\n",
    "                  data['Close'].iloc[i] < data['Middle Band'].iloc[i] and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Evening_Star'\n",
    "            # Doji\n",
    "            elif (abs(data['Close'].iloc[i] - data['Open'].iloc[i]) < data['ATR'].iloc[i] * 0.15 and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Doji'\n",
    "            # Hammer\n",
    "            elif (data['Close'].iloc[i] >= data['Open'].iloc[i] and\n",
    "                  (data['Open'].iloc[i] - data['Low'].iloc[i]) > 2 * abs(data['Close'].iloc[i] - data['Open'].iloc[i]) and\n",
    "                  (data['High'].iloc[i] - data['Close'].iloc[i]) < 0.5 * abs(data['Close'].iloc[i] - data['Open'].iloc[i]) and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i] and\n",
    "                  data['Adjusted'].iloc[i] <= data['Lower Band'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Hammer'\n",
    "            # Shooting Star\n",
    "            elif (data['Close'].iloc[i] <= data['Open'].iloc[i] and\n",
    "                  (data['High'].iloc[i] - data['Open'].iloc[i]) > 2 * abs(data['Close'].iloc[i] - data['Open'].iloc[i]) and\n",
    "                  (data['Close'].iloc[i] - data['Low'].iloc[i]) < 0.5 * abs(data['Close'].iloc[i] - data['Open'].iloc[i]) and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i] and\n",
    "                  data['Adjusted'].iloc[i] >= data['Upper Band'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Shooting_Star'\n",
    "            # Bullish Harami\n",
    "            elif (data['Close'].iloc[i-1] < data['Open'].iloc[i-1] and\n",
    "                  data['Close'].iloc[i] > data['Open'].iloc[i] and\n",
    "                  data['Open'].iloc[i] > data['Close'].iloc[i-1] and\n",
    "                  data['Close'].iloc[i] < data['Open'].iloc[i-1] and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Bullish_Harami'\n",
    "            # Bearish Harami\n",
    "            elif (data['Close'].iloc[i-1] > data['Open'].iloc[i-1] and\n",
    "                  data['Close'].iloc[i] < data['Open'].iloc[i] and\n",
    "                  data['Open'].iloc[i] < data['Close'].iloc[i-1] and\n",
    "                  data['Close'].iloc[i] > data['Open'].iloc[i-1] and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Bearish_Harami'\n",
    "            # Three White Soldiers\n",
    "            elif (i > 2 and\n",
    "                  data['Close'].iloc[i-2] > data['Open'].iloc[i-2] and\n",
    "                  data['Close'].iloc[i-1] > data['Open'].iloc[i-1] and\n",
    "                  data['Close'].iloc[i] > data['Open'].iloc[i] and\n",
    "                  data['Close'].iloc[i] > data['Close'].iloc[i-1] > data['Close'].iloc[i-2] and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Three_White_Soldiers'\n",
    "            # Three Black Crows\n",
    "            elif (i > 2 and\n",
    "                  data['Close'].iloc[i-2] < data['Open'].iloc[i-2] and\n",
    "                  data['Close'].iloc[i-1] < data['Open'].iloc[i-1] and\n",
    "                  data['Close'].iloc[i] < data['Open'].iloc[i] and\n",
    "                  data['Close'].iloc[i] < data['Close'].iloc[i-1] < data['Close'].iloc[i-2] and\n",
    "                  data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]):\n",
    "                data.loc[data.index[i], 'Candlestick_Pattern'] = 'Three_Black_Crows'\n",
    "\n",
    "        # Signal Generation\n",
    "        data['Indicator_Signal'] = 'Hold'\n",
    "        data['Signal_Source'] = np.nan\n",
    "        signal_counts = {}\n",
    "        state = {\n",
    "            'in_position': False,\n",
    "            'trailing_stop': None,\n",
    "            'last_signal_date': None,\n",
    "            'last_signal_type': None\n",
    "        }\n",
    "        cooldown_days_same = 5\n",
    "        cooldown_days_diff = 2\n",
    "\n",
    "        for i in range(50, len(data)):\n",
    "            if pd.isna(data['SMA_50'].iloc[i]) or pd.isna(data['ATR'].iloc[i]):\n",
    "                continue\n",
    "\n",
    "            high_volume = data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]\n",
    "            price_change = abs(data['Adjusted'].iloc[i] - data['Adjusted'].iloc[i-1])\n",
    "            momentum = price_change > data['ATR'].iloc[i] * 0.05\n",
    "            trend = data['Adjusted'].iloc[i] > data['EMA_20'].iloc[i] and data['EMA_20'].iloc[i] > data['EMA_20'].iloc[i-5]\n",
    "\n",
    "            if state['last_signal_date'] is not None:\n",
    "                days_since_last = (data.index[i] - state['last_signal_date']).days\n",
    "                if state['last_signal_type'] in ['Buy', 'Sell'] and days_since_last < cooldown_days_same:\n",
    "                    continue\n",
    "                elif state['last_signal_type'] != data['Indicator_Signal'].iloc[i] and days_since_last < cooldown_days_diff:\n",
    "                    continue\n",
    "\n",
    "            # Indicator Signals\n",
    "            signals = []\n",
    "            sources = []\n",
    "            # Candlestick Patterns\n",
    "            if (data['Candlestick_Pattern'].iloc[i] in ['Bullish_Engulfing', 'Morning_Star', 'Hammer', 'Bullish_Harami', 'Three_White_Soldiers'] and\n",
    "                high_volume and trend and data['Close'].iloc[i] > data['Open'].iloc[i]):\n",
    "                signals.append('Buy')\n",
    "                sources.append(data['Candlestick_Pattern'].iloc[i])\n",
    "            elif (data['Candlestick_Pattern'].iloc[i] in ['Bearish_Engulfing', 'Evening_Star', 'Shooting_Star', 'Bearish_Harami', 'Three_Black_Crows'] and\n",
    "                  high_volume and not trend and data['Close'].iloc[i] < data['Open'].iloc[i]):\n",
    "                if state['in_position']:\n",
    "                    signals.append('Sell')\n",
    "                    sources.append(data['Candlestick_Pattern'].iloc[i])\n",
    "            elif (data['Candlestick_Pattern'].iloc[i] == 'Doji' and\n",
    "                  data['RSI'].iloc[i] > 65 and high_volume and not trend):\n",
    "                if state['in_position']:\n",
    "                    signals.append('Sell')\n",
    "                    sources.append('Doji')\n",
    "            # Non-Candlestick Indicators\n",
    "            if (data['SMA_20'].iloc[i] > data['SMA_50'].iloc[i] and\n",
    "                data['SMA_20'].iloc[i-1] <= data['SMA_50'].iloc[i-1] and\n",
    "                high_volume and momentum and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('SMA_Crossover')\n",
    "            if (data['RSI'].iloc[i] < 35 and \n",
    "                data['RSI'].iloc[i-1] >= 35 and\n",
    "                high_volume and data['RSI'].iloc[i] < data['RSI'].iloc[i-1] and\n",
    "                data['Close'].iloc[i] > data['Open'].iloc[i] and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('RSI_Oversold')\n",
    "            if (data['Low'].iloc[i] <= data['Support'].iloc[i] and\n",
    "                high_volume and momentum and\n",
    "                data['Close'].iloc[i] > data['Open'].iloc[i] and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('Support_Bounce')\n",
    "            if (data['MACD'].iloc[i] > data['MACD_Signal'].iloc[i] and\n",
    "                data['MACD'].iloc[i-1] <= data['MACD_Signal'].iloc[i-1] and\n",
    "                data['MACD_Hist'].iloc[i] > 0 and\n",
    "                high_volume and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('MACD_Crossover')\n",
    "            if (data['Adjusted'].iloc[i] <= data['Lower Band'].iloc[i] and\n",
    "                data['Adjusted'].iloc[i-1] > data['Lower Band'].iloc[i-1] and\n",
    "                high_volume and data['Close'].iloc[i] > data['Open'].iloc[i] and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('Bollinger_Lower')\n",
    "            if (data['Adjusted'].iloc[i] <= data['Fib_61.8'].iloc[i] and\n",
    "                data['Adjusted'].iloc[i-1] > data['Fib_61.8'].iloc[i-1] and\n",
    "                high_volume and momentum and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('Fib_61.8')\n",
    "            if (data['%K'].iloc[i] < 20 and data['%D'].iloc[i] < 20 and\n",
    "                data['%K'].iloc[i] > data['%D'].iloc[i] and\n",
    "                high_volume and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('Stochastic_Oversold')\n",
    "            if state['in_position'] and data['Low'].iloc[i] <= state['trailing_stop']:\n",
    "                signals.append('Sell')\n",
    "                sources.append('Trailing_Stop')\n",
    "            if state['in_position'] and (data['SMA_20'].iloc[i] < data['SMA_50'].iloc[i] and\n",
    "                                        data['SMA_20'].iloc[i-1] >= data['SMA_50'].iloc[i-1] and\n",
    "                                        high_volume and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('SMA_Crossover')\n",
    "            if state['in_position'] and (data['High'].iloc[i] >= data['Resistance'].iloc[i] and\n",
    "                                        high_volume and\n",
    "                                        data['Close'].iloc[i] < data['Open'].iloc[i] and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('Resistance_Rejection')\n",
    "            if state['in_position'] and (data['MACD'].iloc[i] < data['MACD_Signal'].iloc[i] and\n",
    "                                        data['MACD'].iloc[i-1] >= data['MACD_Signal'].iloc[i-1] and\n",
    "                                        data['MACD_Hist'].iloc[i] < 0 and\n",
    "                                        high_volume and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('MACD_Crossover')\n",
    "            if state['in_position'] and (data['Adjusted'].iloc[i] >= data['Upper Band'].iloc[i] and\n",
    "                                        data['Adjusted'].iloc[i-1] < data['Upper Band'].iloc[i-1] and\n",
    "                                        high_volume and data['Close'].iloc[i] < data['Open'].iloc[i] and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('Bollinger_Upper')\n",
    "            if state['in_position'] and (data['Adjusted'].iloc[i] >= data['Fib_23.6'].iloc[i] and\n",
    "                                        data['Adjusted'].iloc[i-1] < data['Fib_23.6'].iloc[i-1] and\n",
    "                                        high_volume and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('Fib_23.6')\n",
    "            if state['in_position'] and (data['%K'].iloc[i] > 80 and data['%D'].iloc[i] > 80 and\n",
    "                                        data['%K'].iloc[i] < data['%D'].iloc[i] and\n",
    "                                        high_volume and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('Stochastic_Overbought')\n",
    "\n",
    "            # Confirmation Logic\n",
    "            if state['in_position'] and signals and signals[0] == 'Sell':\n",
    "                data.loc[data.index[i], 'Indicator_Signal'] = 'Sell'\n",
    "                data.loc[data.index[i], 'Signal_Source'] = sources[0]\n",
    "                signal_counts[sources[0] + '_Sell'] = signal_counts.get(sources[0] + '_Sell', 0) + 1\n",
    "                state['in_position'] = False\n",
    "                state['trailing_stop'] = None\n",
    "                state['last_signal_date'] = data.index[i]\n",
    "                state['last_signal_type'] = 'Sell'\n",
    "                print(f\"Sell Signal at {data.index[i]}: {sources[0]}\")\n",
    "            elif not state['in_position'] and signals and signals[0] == 'Buy':\n",
    "                data.loc[data.index[i], 'Indicator_Signal'] = 'Buy'\n",
    "                data.loc[data.index[i], 'Signal_Source'] = sources[0]\n",
    "                signal_counts[sources[0] + '_Buy'] = signal_counts.get(sources[0] + '_Buy', 0) + 1\n",
    "                state['in_position'] = True\n",
    "                state['trailing_stop'] = data['Adjusted'].iloc[i] - 3.5 * data['ATR'].iloc[i]\n",
    "                state['last_signal_date'] = data.index[i]\n",
    "                state['last_signal_type'] = 'Buy'\n",
    "                print(f\"Buy Signal at {data.index[i]}: {sources[0]}, trailing_stop={state['trailing_stop']}\")\n",
    "            if state['in_position'] and data['Adjusted'].iloc[i] > data['Adjusted'].iloc[i-1]:\n",
    "                new_stop = data['Adjusted'].iloc[i] - 3.5 * data['ATR'].iloc[i]\n",
    "                state['trailing_stop'] = max(state['trailing_stop'], new_stop)\n",
    "\n",
    "        # Remove Confirmed_Signal logic to simplify\n",
    "        data = data.drop(columns=['Confirmed_Signal', 'Confirmed_Signal_Source'], errors='ignore')\n",
    "\n",
    "        print(\"Detected signals:\", signal_counts if signal_counts else \"None\")\n",
    "        if not signal_counts:\n",
    "            print(\"Warning: No signals detected. Check indicator logic or data.\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in signal generation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return data\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "try:\n",
    "    ticker = 'APPLE INC'\n",
    "    data = generate_indicator_signals(data)\n",
    "    \n",
    "    print(\"Columns in DataFrame:\", data.columns.tolist())\n",
    "    print(\"\\nSignal Counts:\")\n",
    "    print(data['Indicator_Signal'].value_counts())\n",
    "    print(\"\\nSignal Source Distribution:\")\n",
    "    print(data['Signal_Source'].value_counts(dropna=False))\n",
    "    \n",
    "    signals = data[data['Indicator_Signal'] != 'Hold']\n",
    "    if not signals.empty:\n",
    "        print(\"\\nSignal Details:\")\n",
    "        print(signals[['Indicator_Signal', 'Signal_Source']].groupby(['Indicator_Signal', 'Signal_Source']).size())\n",
    "        \n",
    "        buy_signals = signals[signals['Indicator_Signal'] == 'Buy']\n",
    "        sell_signals = signals[signals['Indicator_Signal'] == 'Sell']\n",
    "        if not buy_signals.empty and not sell_signals.empty:\n",
    "            durations = []\n",
    "            for buy_date in buy_signals.index:\n",
    "                next_sell = sell_signals[sell_signals.index > buy_date]\n",
    "                if not next_sell.empty:\n",
    "                    sell_date = next_sell.index[0]\n",
    "                    durations.append((sell_date - buy_date).days)\n",
    "            \n",
    "            if durations:\n",
    "                print(f\"\\nAverage Position Duration: {np.mean(durations):.1f} days\")\n",
    "                print(f\"Min Position Duration: {min(durations)} days\")\n",
    "                print(f\"Max Position Duration: {max(durations)} days\")\n",
    "\n",
    "    output_path = r'C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\APPLE_IndicatorSignals.xlsx'\n",
    "    data.to_excel(output_path, sheet_name='Indicator Signals')\n",
    "    print(f\"\\nExcel file saved successfully to: {output_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in signal generation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d98b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade Signals without Candle Sticks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_indicator_signals(data):\n",
    "    try:\n",
    "        # Validate required columns\n",
    "        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            raise ValueError(f\"Missing required columns: {required_columns}\")\n",
    "\n",
    "        # Ensure DateTime index\n",
    "        if not isinstance(data.index, pd.DatetimeIndex):\n",
    "            data.index = pd.to_datetime(data.index)\n",
    "            \n",
    "        # Use Adjusted if available, else Close\n",
    "        if 'Adjusted' not in data.columns:\n",
    "            data['Adjusted'] = data['Close']\n",
    "            \n",
    "        # Check for sufficient data\n",
    "        if len(data) < 50:\n",
    "            raise ValueError(\"Insufficient data for indicators (need at least 50 days).\")\n",
    "\n",
    "        # Indicator Calculations\n",
    "        data['SMA_20'] = data['Adjusted'].rolling(window=20, min_periods=20).mean()\n",
    "        data['SMA_50'] = data['Adjusted'].rolling(window=50, min_periods=50).mean()\n",
    "        data['EMA_20'] = data['Adjusted'].ewm(span=20, adjust=False).mean()\n",
    "        data['Volume_MA'] = data['Volume'].rolling(window=20, min_periods=20).mean()\n",
    "\n",
    "        def calculate_atr(data, window):\n",
    "            hl = data['High'] - data['Low']\n",
    "            hc = abs(data['High'] - data['Close'].shift(1))\n",
    "            lc = abs(data['Low'] - data['Close'].shift(1))\n",
    "            tr = pd.concat([hl, hc, lc], axis=1).max(axis=1)\n",
    "            return tr.rolling(window, min_periods=1).mean()\n",
    "        data['ATR'] = calculate_atr(data, 14)\n",
    "\n",
    "        def calculate_rsi(data, window):\n",
    "            delta = data['Adjusted'].diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            avg_gain = gain.rolling(window, min_periods=window).mean()\n",
    "            avg_loss = loss.rolling(window, min_periods=window).mean()\n",
    "            rs = avg_gain / avg_loss\n",
    "            rs = rs.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            return 100 - (100 / (1 + rs))\n",
    "        data['RSI'] = calculate_rsi(data, 14)\n",
    "\n",
    "        exp1 = data['Adjusted'].ewm(span=12, adjust=False).mean()\n",
    "        exp2 = data['Adjusted'].ewm(span=26, adjust=False).mean()\n",
    "        data['MACD'] = exp1 - exp2\n",
    "        data['MACD_Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "        data['MACD_Hist'] = data['MACD'] - data['MACD_Signal']\n",
    "\n",
    "        data['Middle Band'] = data['Adjusted'].rolling(window=20).mean()\n",
    "        std = data['Adjusted'].rolling(window=20).std()\n",
    "        data['Upper Band'] = data['Middle Band'] + 1.5 * std\n",
    "        data['Lower Band'] = data['Middle Band'] - 1.5 * std\n",
    "\n",
    "        n = 20\n",
    "        data['Rolling_Low'] = data['Low'].rolling(n, min_periods=n).min()\n",
    "        data['Rolling_High'] = data['High'].rolling(n, min_periods=n).max()\n",
    "        data['Support'] = data['Rolling_Low'] + 0.2 * data['ATR']\n",
    "        data['Resistance'] = data['Rolling_High'] - 0.2 * data['ATR']\n",
    "\n",
    "        # Signal Generation\n",
    "        data['Indicator_Signal'] = 'Hold'\n",
    "        data['Signal_Source'] = np.nan\n",
    "        signal_counts = {}\n",
    "        state = {\n",
    "            'in_position': False,\n",
    "            'trailing_stop': None,\n",
    "            'last_signal_date': None,\n",
    "            'last_signal_type': None\n",
    "        }\n",
    "        cooldown_days_same = 5\n",
    "        cooldown_days_diff = 2\n",
    "\n",
    "        for i in range(50, len(data)):\n",
    "            if pd.isna(data['SMA_50'].iloc[i]) or pd.isna(data['ATR'].iloc[i]):\n",
    "                continue\n",
    "\n",
    "            high_volume = data['Volume'].iloc[i] > 0.65 * data['Volume_MA'].iloc[i]\n",
    "            price_change = abs(data['Adjusted'].iloc[i] - data['Adjusted'].iloc[i-1])\n",
    "            momentum = price_change > data['ATR'].iloc[i] * 0.05\n",
    "            trend = data['Adjusted'].iloc[i] > data['EMA_20'].iloc[i] and data['EMA_20'].iloc[i] > data['EMA_20'].iloc[i-5]\n",
    "\n",
    "            if state['last_signal_date'] is not None:\n",
    "                days_since_last = (data.index[i] - state['last_signal_date']).days\n",
    "                if state['last_signal_type'] in ['Buy', 'Sell'] and days_since_last < cooldown_days_same:\n",
    "                    continue\n",
    "                elif state['last_signal_type'] != data['Indicator_Signal'].iloc[i] and days_since_last < cooldown_days_diff:\n",
    "                    continue\n",
    "\n",
    "            # Indicator Signals\n",
    "            signals = []\n",
    "            sources = []\n",
    "            if (data['SMA_20'].iloc[i] > data['SMA_50'].iloc[i] and\n",
    "                data['SMA_20'].iloc[i-1] <= data['SMA_50'].iloc[i-1] and\n",
    "                high_volume and momentum and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('SMA_Crossover')\n",
    "            if (data['RSI'].iloc[i] < 35 and \n",
    "                data['RSI'].iloc[i-1] >= 35 and\n",
    "                high_volume and data['RSI'].iloc[i] < data['RSI'].iloc[i-1] and\n",
    "                data['Close'].iloc[i] > data['Open'].iloc[i]):\n",
    "                signals.append('Buy')\n",
    "                sources.append('RSI_Oversold')\n",
    "            if (data['Low'].iloc[i] <= data['Support'].iloc[i] and\n",
    "                high_volume and momentum and\n",
    "                data['Close'].iloc[i] > data['Open'].iloc[i] and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('Support_Bounce')\n",
    "            if (data['MACD'].iloc[i] > data['MACD_Signal'].iloc[i] and\n",
    "                data['MACD'].iloc[i-1] <= data['MACD_Signal'].iloc[i-1] and\n",
    "                data['MACD_Hist'].iloc[i] > 0 and\n",
    "                high_volume and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('MACD_Crossover')\n",
    "            if (data['Adjusted'].iloc[i] <= data['Lower Band'].iloc[i] and\n",
    "                data['Adjusted'].iloc[i-1] > data['Lower Band'].iloc[i-1] and\n",
    "                high_volume and data['Close'].iloc[i] > data['Open'].iloc[i] and trend):\n",
    "                signals.append('Buy')\n",
    "                sources.append('Bollinger_Lower')\n",
    "            if state['in_position'] and data['Low'].iloc[i] <= state['trailing_stop']:\n",
    "                signals.append('Sell')\n",
    "                sources.append('Trailing_Stop')\n",
    "            if state['in_position'] and (data['SMA_20'].iloc[i] < data['SMA_50'].iloc[i] and\n",
    "                                        data['SMA_20'].iloc[i-1] >= data['SMA_50'].iloc[i-1] and\n",
    "                                        high_volume and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('SMA_Crossover')\n",
    "            if state['in_position'] and (data['High'].iloc[i] >= data['Resistance'].iloc[i] and\n",
    "                                        high_volume and\n",
    "                                        data['Close'].iloc[i] < data['Open'].iloc[i] and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('Resistance_Rejection')\n",
    "            if state['in_position'] and (data['MACD'].iloc[i] < data['MACD_Signal'].iloc[i] and\n",
    "                                        data['MACD'].iloc[i-1] >= data['MACD_Signal'].iloc[i-1] and\n",
    "                                        data['MACD_Hist'].iloc[i] < 0 and\n",
    "                                        high_volume and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('MACD_Crossover')\n",
    "            if state['in_position'] and (data['Adjusted'].iloc[i] >= data['Upper Band'].iloc[i] and\n",
    "                                        data['Adjusted'].iloc[i-1] < data['Upper Band'].iloc[i-1] and\n",
    "                                        high_volume and data['Close'].iloc[i] < data['Open'].iloc[i] and not trend):\n",
    "                signals.append('Sell')\n",
    "                sources.append('Bollinger_Upper')\n",
    "\n",
    "            # Confirmation Logic\n",
    "            if state['in_position'] and signals and signals[0] == 'Sell':\n",
    "                data.loc[data.index[i], 'Indicator_Signal'] = 'Sell'\n",
    "                data.loc[data.index[i], 'Signal_Source'] = sources[0]\n",
    "                signal_counts[sources[0] + '_Sell'] = signal_counts.get(sources[0] + '_Sell', 0) + 1\n",
    "                state['in_position'] = False\n",
    "                state['trailing_stop'] = None\n",
    "                state['last_signal_date'] = data.index[i]\n",
    "                state['last_signal_type'] = 'Sell'\n",
    "                print(f\"Sell Signal at {data.index[i]}: {sources[0]}\")\n",
    "            elif not state['in_position'] and signals and signals[0] == 'Buy':\n",
    "                data.loc[data.index[i], 'Indicator_Signal'] = 'Buy'\n",
    "                data.loc[data.index[i], 'Signal_Source'] = sources[0]\n",
    "                signal_counts[sources[0] + '_Buy'] = signal_counts.get(sources[0] + '_Buy', 0) + 1\n",
    "                state['in_position'] = True\n",
    "                state['trailing_stop'] = data['Adjusted'].iloc[i] - 3.5 * data['ATR'].iloc[i]\n",
    "                state['last_signal_date'] = data.index[i]\n",
    "                state['last_signal_type'] = 'Buy'\n",
    "                print(f\"Buy Signal at {data.index[i]}: {sources[0]}, trailing_stop={state['trailing_stop']}\")\n",
    "            if state['in_position'] and data['Adjusted'].iloc[i] > data['Adjusted'].iloc[i-1]:\n",
    "                new_stop = data['Adjusted'].iloc[i] - 3.5 * data['ATR'].iloc[i]\n",
    "                state['trailing_stop'] = max(state['trailing_stop'], new_stop)\n",
    "\n",
    "        print(\"Detected signals:\", signal_counts if signal_counts else \"None\")\n",
    "        if not signal_counts:\n",
    "            print(\"Warning: No signals detected. Check indicator logic or data.\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in signal generation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return data\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "try:\n",
    "    ticker = 'APPLE INC'\n",
    "    data = generate_indicator_signals(data)\n",
    "    \n",
    "    print(\"Columns in DataFrame:\", data.columns.tolist())\n",
    "    print(\"\\nSignal Counts:\")\n",
    "    print(data['Indicator_Signal'].value_counts())\n",
    "    print(\"\\nSignal Source Distribution:\")\n",
    "    print(data['Signal_Source'].value_counts(dropna=False))\n",
    "    \n",
    "    signals = data[data['Indicator_Signal'] != 'Hold']\n",
    "    if not signals.empty:\n",
    "        print(\"\\nSignal Details:\")\n",
    "        print(signals[['Indicator_Signal', 'Signal_Source']].groupby(['Indicator_Signal', 'Signal_Source']).size())\n",
    "        \n",
    "        buy_signals = signals[signals['Indicator_Signal'] == 'Buy']\n",
    "        sell_signals = signals[signals['Indicator_Signal'] == 'Sell']\n",
    "        if not buy_signals.empty and not sell_signals.empty:\n",
    "            durations = []\n",
    "            for buy_date in buy_signals.index:\n",
    "                next_sell = sell_signals[sell_signals.index > buy_date]\n",
    "                if not next_sell.empty:\n",
    "                    sell_date = next_sell.index[0]\n",
    "                    durations.append((sell_date - buy_date).days)\n",
    "            \n",
    "            if durations:\n",
    "                print(f\"\\nAverage Position Duration: {np.mean(durations):.1f} days\")\n",
    "                print(f\"Min Position Duration: {min(durations)} days\")\n",
    "                print(f\"Max Position Duration: {max(durations)} days\")\n",
    "\n",
    "    output_path = r'C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\APPLE_IndicatorSignals.xlsx'\n",
    "    data.to_excel(output_path, sheet_name='Indicator Signals')\n",
    "    print(f\"\\nExcel file saved successfully to: {output_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in signal generation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_signal(data, signal_type, max_plots=3):\n",
    "    try:\n",
    "        required_columns = ['Open', 'High', 'Low', 'Close', 'Indicator_Signal']\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {data.columns}\")\n",
    "\n",
    "        if not isinstance(data.index, pd.DatetimeIndex):\n",
    "            raise ValueError(\"DataFrame index must be a DateTimeIndex.\")\n",
    "    \n",
    "        signal_data = data[data['Indicator_Signal'] == signal_type]\n",
    "        if signal_data.empty:\n",
    "            print(f\"No occurrences of {signal_type} signals found.\")\n",
    "            return 0\n",
    "\n",
    "        plot_count = 0\n",
    "        skipped_dates = []\n",
    "        for date in signal_data.index:\n",
    "            if plot_count >= max_plots:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                idx = data.index.get_loc(date)\n",
    "                start_idx = max(0, idx - 3)\n",
    "                end_idx = min(len(data), idx + 4)\n",
    "                window = data.iloc[start_idx:end_idx].copy()\n",
    "                window = window.dropna(subset=['Open', 'High', 'Low', 'Close'])\n",
    "\n",
    "                if len(window) < 2:\n",
    "                    skipped_dates.append(date.date())\n",
    "                    print(f\"Skipped {signal_type} plot for {date.date()}: Insufficient data points ({len(window)})\")\n",
    "                    continue\n",
    "\n",
    "                data_ohlc = window[['Open', 'High', 'Low', 'Close']].copy()\n",
    "                data_ohlc.reset_index(inplace=True)\n",
    "                data_ohlc['Date'] = data_ohlc['Date'].map(mdates.date2num)\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(10, 5))\n",
    "                candlestick_ohlc(ax, data_ohlc.values, width=0.6, colorup='g', colordown='r')\n",
    "\n",
    "                signal_date_num = mdates.date2num([date])[0]\n",
    "                signal_source = data.loc[date, 'Signal_Source']\n",
    "                if signal_type == 'Buy':\n",
    "                    ax.scatter([signal_date_num], [window['Low'].min() * 0.98], marker='^', color='blue', s=100, label=f'Buy Signal ({signal_source})')\n",
    "                elif signal_type == 'Sell':\n",
    "                    ax.scatter([signal_date_num], [window['High'].max() * 1.02], marker='v', color='red', s=100, label=f'Sell Signal ({signal_source})')\n",
    "\n",
    "                ax.xaxis_date()\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "                ax.set_title(f'{signal_type} Signal on {date.date()} ({signal_source})')\n",
    "                ax.set_xlabel('Date')\n",
    "                ax.set_ylabel('Price')\n",
    "                ax.legend()\n",
    "                ax.grid(True)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                plot_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                skipped_dates.append(date.date())\n",
    "                print(f\"Error plotting {signal_type} on {date.date()}: {e}\")\n",
    "\n",
    "        print(f\"Generated {plot_count} {signal_type} plots.\")\n",
    "        if skipped_dates:\n",
    "            print(f\"Skipped {signal_type} plots for dates: {skipped_dates}\")\n",
    "        return plot_count\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualization: {e}\")\n",
    "        return 0\n",
    "\n",
    "try:\n",
    "    total_plots = 0\n",
    "    for signal in ['Buy', 'Sell']:\n",
    "        total_plots += plot_signal(data, signal, max_plots=3)\n",
    "    print(f\"Total plots generated: {total_plots}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in signal visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy Performance\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def calculate_strategy_performance(df):\n",
    "    try:\n",
    "        required_columns = ['Indicator_Signal', 'Adjusted']\n",
    "        if not all(col in df.columns for col in required_columns):\n",
    "            raise ValueError(f\"Missing required columns: {required_columns}. Available columns: {df.columns}\")\n",
    "\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            raise ValueError(\"DataFrame index must be a DateTimeIndex.\")\n",
    "\n",
    "        df['Position'] = 0\n",
    "        df['Strategy_Returns'] = 0.0\n",
    "        df['Market_Returns'] = df['Adjusted'].pct_change().fillna(0)\n",
    "        transaction_cost = 0.001\n",
    "\n",
    "        position = 0\n",
    "        trade_details = []\n",
    "        buy_price = None\n",
    "        buy_date = None\n",
    "        buy_source = None\n",
    "        for i in range(1, len(df)):\n",
    "            if df.loc[df.index[i], 'Indicator_Signal'] == 'Buy' and position == 0:\n",
    "                position = 1\n",
    "                buy_price = df['Adjusted'].iloc[i]\n",
    "                buy_date = df.index[i]\n",
    "                buy_source = df['Signal_Source'].iloc[i]\n",
    "            elif df.loc[df.index[i], 'Indicator_Signal'] == 'Sell' and position == 1:\n",
    "                position = 0\n",
    "                sell_price = df['Adjusted'].iloc[i]\n",
    "                sell_date = df.index[i]\n",
    "                sell_source = df['Signal_Source'].iloc[i]\n",
    "                if buy_price is not None:\n",
    "                    trade_return = (sell_price / buy_price - 1) - 2 * transaction_cost\n",
    "                    trade_details.append({\n",
    "                        'Buy_Date': buy_date,\n",
    "                        'Sell_Date': sell_date,\n",
    "                        'Buy_Source': buy_source,\n",
    "                        'Sell_Source': sell_source,\n",
    "                        'Return': trade_return,\n",
    "                        'Holding_Period': (sell_date - buy_date).days\n",
    "                    })\n",
    "            df.loc[df.index[i], 'Position'] = position\n",
    "            df.loc[df.index[i], 'Strategy_Returns'] = position * df.loc[df.index[i], 'Market_Returns'] - transaction_cost * abs(df['Position'].iloc[i] - df['Position'].iloc[i-1])\n",
    "\n",
    "        df['Cumulative_Strategy_Returns'] = (1 + df['Strategy_Returns']).cumprod() - 1\n",
    "        df['Cumulative_Market_Returns'] = (1 + df['Market_Returns']).cumprod() - 1\n",
    "\n",
    "        days = (df.index[-1] - df.index[0]).days\n",
    "        years = days / 365.25\n",
    "        annual_trading_days = 252\n",
    "        strategy_total_return = df['Cumulative_Strategy_Returns'].iloc[-1]\n",
    "        market_total_return = df['Cumulative_Market_Returns'].iloc[-1]\n",
    "        strategy_annualized_return = (1 + strategy_total_return) ** (1 / years) - 1\n",
    "        market_annualized_return = (1 + market_total_return) ** (1 / years) - 1\n",
    "        strategy_volatility = df['Strategy_Returns'].std() * np.sqrt(annual_trading_days)\n",
    "        market_volatility = df['Market_Returns'].std() * np.sqrt(annual_trading_days)\n",
    "        downside_vol_strategy = df[df['Strategy_Returns'] < 0]['Strategy_Returns'].std() * np.sqrt(annual_trading_days)\n",
    "        downside_vol_market = df[df['Market_Returns'] < 0]['Market_Returns'].std() * np.sqrt(annual_trading_days)\n",
    "        sharpe_ratio_strategy = strategy_annualized_return / strategy_volatility if strategy_volatility != 0 else np.nan\n",
    "        sharpe_ratio_market = market_annualized_return / market_volatility if market_volatility != 0 else np.nan\n",
    "        sortino_ratio_strategy = strategy_annualized_return / downside_vol_strategy if downside_vol_strategy != 0 else np.nan\n",
    "        sortino_ratio_market = market_annualized_return / downside_vol_market if downside_vol_market != 0 else np.nan\n",
    "        max_drawdown_strategy = (df['Cumulative_Strategy_Returns'].cummax() - df['Cumulative_Strategy_Returns']).max()\n",
    "        max_drawdown_market = (df['Cumulative_Market_Returns'].cummax() - df['Cumulative_Market_Returns']).max()\n",
    "        trades = len(trade_details)\n",
    "        win_rate = len([t for t in trade_details if t['Return'] > 0]) / trades if trades > 0 else 0\n",
    "        avg_holding_period = np.mean([t['Holding_Period'] for t in trade_details]) if trade_details else 0\n",
    "\n",
    "        # Signal Quality Metrics\n",
    "        signal_hit_ratios = {}\n",
    "        for source in df['Signal_Source'].dropna().unique():\n",
    "            source_trades = [t for t in trade_details if t['Buy_Source'] == source or t['Sell_Source'] == source]\n",
    "            if source_trades:\n",
    "                source_win_rate = len([t for t in source_trades if t['Return'] > 0]) / len(source_trades)\n",
    "                signal_hit_ratios[source] = source_win_rate\n",
    "\n",
    "        print(f\"Indicator Strategy Performance Metrics:\")\n",
    "        print(f\"  Annualized Return: {strategy_annualized_return:.4f}\")\n",
    "        print(f\"  Volatility: {strategy_volatility:.4f}\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio_strategy:.4f}\")\n",
    "        print(f\"  Sortino Ratio: {sortino_ratio_strategy:.4f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown_strategy:.4f}\")\n",
    "        print(f\"  Number of Trades: {trades:.0f}\")\n",
    "        print(f\"  Win Rate: {win_rate:.4f}\")\n",
    "        print(f\"  Average Holding Period: {avg_holding_period:.1f} days\")\n",
    "        print(f\"Market (Buy-and-Hold) Performance Metrics:\")\n",
    "        print(f\"  Annualized Return: {market_annualized_return:.4f}\")\n",
    "        print(f\"  Volatility: {market_volatility:.4f}\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio_market:.4f}\")\n",
    "        print(f\"  Sortino Ratio: {sortino_ratio_market:.4f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown_market:.4f}\")\n",
    "        print(\"Signal Source Distribution:\")\n",
    "        print(df['Signal_Source'].value_counts(dropna=False))\n",
    "        print(\"Signal Counts:\")\n",
    "        print(df['Indicator_Signal'].value_counts())\n",
    "        print(\"Trade Dates:\")\n",
    "        trade_dates = df[df['Position'].diff().abs() > 0][['Indicator_Signal', 'Signal_Source', 'Adjusted']]\n",
    "        print(trade_dates)\n",
    "        print(\"Signal Profitability by Source:\")\n",
    "        print(df[df['Strategy_Returns'] != 0].groupby('Signal_Source')['Strategy_Returns'].mean())\n",
    "        print(\"Individual Trade Details:\")\n",
    "        for t in trade_details:\n",
    "            print(f\"Buy: {t['Buy_Date'].date()} ({t['Buy_Source']}) -> Sell: {t['Sell_Date'].date()} ({t['Sell_Source']}), Return: {t['Return']:.4f}, Holding: {t['Holding_Period']} days\")\n",
    "        print(\"Signal Hit Ratios by Source:\")\n",
    "        for source, hit_ratio in signal_hit_ratios.items():\n",
    "            print(f\"{source}: {hit_ratio:.4f}\")\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df.index, df['Cumulative_Strategy_Returns'], label='Indicator Strategy Returns')\n",
    "        plt.plot(df.index, df['Cumulative_Market_Returns'], label='Market Returns (Buy and Hold)')\n",
    "        plt.title(f'APPLE INC Indicator Strategy Performance vs. Market')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Cumulative Returns')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in performance evaluation: {e}\")\n",
    "        return df\n",
    "\n",
    "try:\n",
    "    ticker = 'APPLE INC'\n",
    "    data = calculate_strategy_performance(data)\n",
    "    print(\"Columns in DataFrame:\", data.columns.tolist())\n",
    "\n",
    "    output_path = r'C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\APPLE_IndicatorStrategy.xlsx'\n",
    "    data.to_excel(output_path, sheet_name='Strategy Performance')\n",
    "    print(\"Excel file generated successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in strategy performance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae52b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliot Wave Theory Demonstration\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Function to identify Elliott Waves\n",
    "def identify_elliott_waves(data, prominence=20):\n",
    "    peaks, _ = find_peaks(data['Adjusted'], prominence=prominence)\n",
    "    troughs, _ = find_peaks(-data['Adjusted'], prominence=prominence)\n",
    "    return peaks, troughs\n",
    "\n",
    "# Function to validate impulse wave rules\n",
    "def is_valid_impulse_wave(data, wave_points):\n",
    "    # Wave 2 should not retrace more than 100% of Wave 1\n",
    "    if data['Adjusted'].iloc[wave_points[1]] >= data['Adjusted'].iloc[wave_points[0]]:\n",
    "        return False\n",
    "    # Wave 3 should not be the shortest and should surpass Wave 1\n",
    "    if (data['Adjusted'].iloc[wave_points[2]] <= data['Adjusted'].iloc[wave_points[0]]) or \\\n",
    "       (data['Adjusted'].iloc[wave_points[2]] <= data['Adjusted'].iloc[wave_points[4]]):\n",
    "        return False\n",
    "    # Wave 4 should not overlap with the price range of Wave 1\n",
    "    if data['Adjusted'].iloc[wave_points[3]] >= data['Adjusted'].iloc[wave_points[1]]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Identify potential Elliott Waves\n",
    "peaks, troughs = identify_elliott_waves(data, prominence=20)\n",
    "\n",
    "# Debugging: Print identified peaks and troughs\n",
    "print(\"Peaks identified at:\", peaks)\n",
    "print(\"Troughs identified at:\", troughs)\n",
    "\n",
    "# Looking for impulse wave (5-wave pattern)\n",
    "impulse_wave = []\n",
    "for i in range(len(peaks) - 4):\n",
    "    potential_wave = peaks[i:i+5]\n",
    "    if is_valid_impulse_wave(data, potential_wave):\n",
    "        impulse_wave = potential_wave\n",
    "        print(\"Valid impulse wave found:\", impulse_wave)\n",
    "        break\n",
    "\n",
    "# Plotting the data with peaks and troughs\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.plot(data.index, data['Adjusted'], label='Adj Close Price')\n",
    "\n",
    "# Plot peaks and troughs\n",
    "ax.scatter(data.index[peaks], data['Adjusted'].iloc[peaks], marker='^', color='red', label='Peaks')\n",
    "ax.scatter(data.index[troughs], data['Adjusted'].iloc[troughs], marker='v', color='blue', label='Troughs')\n",
    "\n",
    "# Annotate Impulse Waves if valid impulse wave is found\n",
    "if len(impulse_wave) > 0:\n",
    "    wave_labels = ['Wave 1', 'Wave 2', 'Wave 3', 'Wave 4', 'Wave 5']\n",
    "    for i, peak in enumerate(impulse_wave):\n",
    "        ax.annotate(wave_labels[i], (data.index[peak], data['Adjusted'].iloc[peak]), \n",
    "                    textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=12, color='black')\n",
    "\n",
    "ax.set_title(f'{ticker} - Elliott Wave Impulse Identification')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Price')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a809642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Use adjusted close price for analysis\n",
    "price = data['Adjusted']\n",
    "\n",
    "# Identify peaks and troughs with adjusted parameters\n",
    "peaks, _ = find_peaks(price, distance=30, prominence=5)\n",
    "troughs, _ = find_peaks(-price, distance=30, prominence=5)\n",
    "\n",
    "# Plot the price data with peaks and troughs to verify detection\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(price, label='Adj Close Price')\n",
    "\n",
    "# Plot the peaks and troughs for verification\n",
    "plt.plot(price.index[peaks], price.iloc[peaks], 'r^', label='Peaks')\n",
    "plt.plot(price.index[troughs], price.iloc[troughs], 'bv', label='Troughs')\n",
    "\n",
    "plt.title(f'{ticker} - Peaks and Troughs Identification')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# Function to label Elliott Waves (impulse)\n",
    "def label_elliott_waves(peaks, troughs, price, flexibility=0.15):\n",
    "    wave_labels = {}\n",
    "    wave_count = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(peaks) - 4 and i < len(troughs) - 4:\n",
    "        # Identify candidate points for the waves\n",
    "        wave_1 = troughs[i]\n",
    "        wave_2 = peaks[i + 1]\n",
    "        wave_3 = troughs[i + 2]\n",
    "        wave_4 = peaks[i + 3]\n",
    "        wave_5 = troughs[i + 4]\n",
    "\n",
    "        # Validate wave sequence (prioritize correct order)\n",
    "        if wave_1 < wave_2 and wave_2 < wave_3 and wave_3 < wave_4 and wave_4 < wave_5:\n",
    "            # Conditions to identify a valid impulse wave pattern, with flexibility\n",
    "            if (price.iloc[wave_1] < price.iloc[wave_3] < price.iloc[wave_5] + price.iloc[wave_3] * flexibility) and \\\n",
    "               (price.iloc[wave_2] > price.iloc[wave_4] - price.iloc[wave_2] * flexibility) and \\\n",
    "               (price.iloc[wave_3] < price.iloc[wave_4]) and \\\n",
    "               (price.iloc[wave_3] < price.iloc[wave_5]):\n",
    "\n",
    "                # Check for overlapping waves\n",
    "                if not any(wave in wave_labels.values() for wave in [wave_1, wave_2, wave_3, wave_4, wave_5]):\n",
    "                    wave_count += 1\n",
    "                    wave_labels[f'Wave 1-{wave_count}'] = wave_1\n",
    "                    wave_labels[f'Wave 2-{wave_count}'] = wave_2\n",
    "                    wave_labels[f'Wave 3-{wave_count}'] = wave_3\n",
    "                    wave_labels[f'Wave 4-{wave_count}'] = wave_4\n",
    "                    wave_labels[f'Wave 5-{wave_count}'] = wave_5\n",
    "                    i += 5  # Move forward by 5 to avoid overlapping wave detection\n",
    "                else:\n",
    "                    i += 1  # Move to the next potential wave set\n",
    "            else:\n",
    "                i += 1  # Move to the next potential wave set\n",
    "        else:\n",
    "            i += 1  # Move to the next potential wave set\n",
    "\n",
    "    return wave_labels\n",
    "\n",
    "# Apply the function to label the waves\n",
    "wave_labels = label_elliott_waves(peaks, troughs, price)\n",
    "\n",
    "# If no waves are found, print a warning message\n",
    "if not wave_labels:\n",
    "    print(\"No valid Elliott Waves found.\")\n",
    "\n",
    "# Plot the identified waves on top of the price data\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(price, label='Adj Close Price')\n",
    "\n",
    "# Plot the peaks and troughs for verification\n",
    "plt.plot(price.index[peaks], price.iloc[peaks], 'r^', label='Peaks')\n",
    "plt.plot(price.index[troughs], price.iloc[troughs], 'bv', label='Troughs')\n",
    "\n",
    "# Annotate the identified waves if any\n",
    "for wave, index in wave_labels.items():\n",
    "    plt.annotate(wave, (price.index[index], price.iloc[index]),\n",
    "                 textcoords=\"offset points\", xytext=(-10, 10), ha='center')\n",
    "\n",
    "plt.title(f'{ticker} - Elliott Wave Impulse Identification')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1de421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ichimoku Cloud\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ichimoku Cloud\n",
    "data['Tenkan-sen'] = (data['High'].rolling(window=9).max() + data['Low'].rolling(window=9).min()) / 2\n",
    "data['Kijun-sen'] = (data['High'].rolling(window=26).max() + data['Low'].rolling(window=26).min()) / 2\n",
    "data['Senkou Span A'] = ((data['Tenkan-sen'] + data['Kijun-sen']) / 2).shift(26)\n",
    "data['Senkou Span B'] = ((data['High'].rolling(window=52).max() + data['Low'].rolling(window=52).min()) / 2).shift(26)\n",
    "data['Chikou Span'] = data['Adjusted'].shift(-26)\n",
    "\n",
    "# Plot Ichimoku Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(data['Adjusted'], label='Adj Close Price')\n",
    "plt.plot(data['Tenkan-sen'], label='Tenkan-sen')\n",
    "plt.plot(data['Kijun-sen'], label='Kijun-sen')\n",
    "plt.fill_between(data.index, data['Senkou Span A'], data['Senkou Span B'], where=(data['Senkou Span A'] >= data['Senkou Span B']), color='lightgreen', alpha=0.5)\n",
    "plt.fill_between(data.index, data['Senkou Span A'], data['Senkou Span B'], where=(data['Senkou Span A'] < data['Senkou Span B']), color='lightcoral', alpha=0.5)\n",
    "plt.plot(data['Chikou Span'], label='Chikou Span')\n",
    "plt.title(f'{ticker} Ichimoku Cloud')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8f7e7",
   "metadata": {},
   "source": [
    "### Predictive Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f016448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the CSV file\n",
    "ticker = 'APPLE INC'\n",
    "path = r\"C:\\Users\\IMI\\Documents\\Courses\\SAPM\\AY 2025-26\\R-Exercises\\AAPL.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Ensure the index is a DateTime index (assuming the CSV has a 'Date' column)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b57187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check for stationarity\n",
    "result = adfuller(data['Close'])\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "for key, value in result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(211)\n",
    "plot_acf(data['Close'].diff().dropna(), ax=plt.gca())\n",
    "plt.subplot(212)\n",
    "plot_pacf(data['Close'].diff().dropna(), ax=plt.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ad963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differencing the series for stationarity\n",
    "\n",
    "data['Close_diff'] = data['Close'].diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting an ARIMA Model\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit ARIMA model\n",
    "model = ARIMA(data['Close'], order=(1, 1, 1))  # Use the values from ACF and PACF plots\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7912439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Residuals\n",
    "\n",
    "residuals = model_fit.resid\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(211)\n",
    "plt.plot(residuals)\n",
    "plt.subplot(212)\n",
    "plot_acf(residuals, ax=plt.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast using the model\n",
    "forecast_steps = 30\n",
    "forecast = model_fit.forecast(steps=forecast_steps)\n",
    "forecast_index = pd.date_range(start=data.index[-1], periods=forecast_steps, freq='D')\n",
    "\n",
    "# Plot the actual and forecasted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data.index, data['Close'], label='Actual')\n",
    "plt.plot(forecast_index, forecast, label='Forecast')\n",
    "plt.legend()\n",
    "plt.title(f'{ticker} ARIMA Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic ARIMA Model\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Function to find the best ARIMA model based on AIC\n",
    "def find_best_arima_model(data, max_p, max_d, max_q):\n",
    "    best_aic = float(\"inf\")\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "    \n",
    "    for p in range(max_p + 1):\n",
    "        for d in range(max_d + 1):\n",
    "            for q in range(max_q + 1):\n",
    "                try:\n",
    "                    model = ARIMA(data['Close'], order=(p, d, q))\n",
    "                    model_fit = model.fit()\n",
    "                    aic = model_fit.aic\n",
    "                    if aic < best_aic:\n",
    "                        best_aic = aic\n",
    "                        best_order = (p, d, q)\n",
    "                        best_model = model_fit\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return best_order, best_model\n",
    "\n",
    "# Set the range for p, d, q\n",
    "max_p = 5\n",
    "max_d = 2\n",
    "max_q = 5\n",
    "\n",
    "# Find the best ARIMA model\n",
    "best_order, best_model = find_best_arima_model(data, max_p, max_d, max_q)\n",
    "\n",
    "# Print the best model summary\n",
    "print(f\"Best ARIMA order: {best_order}\")\n",
    "print(best_model.summary())\n",
    "\n",
    "# Forecast using the best model\n",
    "forecast = best_model.forecast(steps=30)\n",
    "forecast_index = pd.date_range(start=data.index[-1], periods=30, freq='D')\n",
    "\n",
    "# Plot the actual and forecasted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data.index, data['Close'], label='Actual')\n",
    "plt.plot(forecast_index, forecast, label='Forecast')\n",
    "plt.legend()\n",
    "plt.title(f'{ticker} ARIMA Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Smoothing Model\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Fit ETS model\n",
    "model = ExponentialSmoothing(data['Close'], trend='add', seasonal='add', seasonal_periods=12)\n",
    "model_fit = model.fit()\n",
    "forecast_steps = 30\n",
    "forecast = model_fit.forecast(steps=forecast_steps)\n",
    "\n",
    "# Print the forecast to verify\n",
    "#print(forecast)\n",
    "\n",
    "# Generate forecast index\n",
    "forecast_index = pd.date_range(start=data.index[-1] + pd.Timedelta(days=1), periods=forecast_steps, freq='D')\n",
    "\n",
    "# Print the forecast index to verify\n",
    "#print(forecast_index)\n",
    "\n",
    "# Create a DataFrame for the forecast to ensure proper indexing\n",
    "forecast_series = pd.Series(forecast.values, index=forecast_index)\n",
    "\n",
    "# Print the forecast series to verify\n",
    "print(forecast_series)\n",
    "\n",
    "# Plot the actual and forecasted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data.index, data['Close'], label='Actual')\n",
    "plt.plot(forecast_series.index, forecast_series, label='Forecast', color='orange')\n",
    "plt.legend()\n",
    "plt.title(f'{ticker} Exponential Smoothing Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9652d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
